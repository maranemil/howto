#############################################
Run an unlocked LLM on your desktop in 15 minutes - 6GB RAM 6 CPU
#############################################

sudo apt install curl -y
curl -fsSL https://ollama.com/install.sh | sh

ollama run qwen3:0.6b

https://docs.docker.com/engine/install/linux-postinstall/

sudo apt install docker.io -y
sudo groupadd docker
sudo usermod -aG docker $USER
exec su -l $USER
docker run hello-world

ollama list

check
http://localhost:11434/
http://127.0.0.1:11434/

systemctl daemon-reload
systemctl restart ollama

docker run -d -p 3000:8080 -e OLLAMA_API_BASE_URL=http://host.docker.internal:11434/api -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
Open your browser and go to: http://localhost:3000

sudo apt install python3-pip
pip install ollama


##########################################
codellama
##########################################


https://ollama.com/library/qwen3:0.6b
https://ollama.com/library/qwen3:1.7b
https://ollama.com/library/qwen3:4b
https://ollama.com/library/qwen3
https://ollama.com/library/qwen2.5
https://ollama.com/library/mistral   4GB
https://ollama.com/library/deepseek-r1:1.5b
https://ollama.com/library/qwen2.5vl:3b
https://ollama.com/library/llama3.1:8b
https://ollama.com/library/qwen2.5:1.5b
https://ollama.com/library/qwen2.5-coder:1.5b
https://ollama.com/library/gemma2:2b
https://ollama.com/library/qwen:1.8b
https://ollama.com/library/codellama:7b
https://ollama.com/library/tinyllama:latest
https://ollama.com/library/deepseek-coder:6.7b
https://ollama.com/library/phi3.5:latest
https://ollama.com/library/phi4-mini:latest
https://ollama.com/library/tinydolphin:latest
https://ollama.com/library/qwen2-math:1.5b
https://ollama.com/library/deepcoder:1.5b
https://ollama.com/library/sqlcoder:7b
https://ollama.com/library/yi-coder:1.5b
https://ollama.com/library/mistrallite:latest

...

https://blog.codegpt.co/create-your-own-and-custom-copilot-in-vscode-with-ollama-and-codegpt-736277a60298

https://ollama.com/library/codellama
ollama pull codellama
ollama list
ollama run codellama


Modelfile
~~~
FROM codellama

# sets the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# sets the context window size to 1500, this controls how many tokens the LLM can use as context to generate the next token
PARAMETER num_ctx 1500

# sets a custom system message to specify the behavior of the chat assistant
SYSTEM You are expert Code Assistant
~~~


ollama create codegpt-codellama -f ./Codellama/Modelfile
ollama run codegpt-codellama

CodeGPT extension
https://marketplace.visualstudio.com/items?itemName=DanielSanMedium.dscodegpt
https://marketplace.visualstudio.com/items?itemName=AnikGhosh.ollama-copilot

#########################################################
generative image
#########################################################

ollama run llava:7b
ollama run llava "describe this image: ./art.jpg"
ollama run llava "tell me what do you see in this picture? ./pic.jpg"
ollama run llava "what does the text say? ./wordart.png"

https://www.byteplus.com/en/topic/398500?title=ollama-models-that-can-generate-images-a-comprehensive-guide-to-ai-image-creation

# Install Ollama
curl https://ollama.ai/install.sh | sh
# Pull a vision model
ollama pull llava:13b
# Verify installation
ollama list
from ollama import generate
# Generate an image with a text prompt
image = generate(
    model='llava:13b',
    prompt='A futuristic cityscape at sunset',
    max_tokens=1024
)


https://voipnuggets.com/2024/05/25/open-web-ui-run-local-chat-app-with-image-generation-using-phi4-deepseek-r1-and-stable-diffusion/

docker --version
ollama --version
ollama pull deepseek-r1
ollama pull phi4

1. pip install virtualenv
2. python3.10 -m venv stable-diffusion-env
3. For Bash/Zsh: 
source stable-diffusion-env/bin/activate
For Fish Shell: 
source stable-diffusion-env/bin/activate.fish
4. python --version

1. git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
2. cd stable-diffusion-webui
3. ./webui.sh --api --listen
git clone git@github.com:open-webui/open-webui.git
	
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -e AUTOMATIC1111_BASE_URL=http://host.docker.internal:7860/ -e ENABLE_IMAGE_GENERATION=True -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main

 access the web interface at http://127.0.0.1:3000.

