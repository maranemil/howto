
#####################################################
ollama Llama Gemma
#####################################################
https://www.youtube.com/watch?v=DYhC7nFRL5I
https://ollama.com/download
https://ollama.com/library/dolphin-llama3
https://www.llama.com/
https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_3/
https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md
https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct
https://github.com/ollama
https://ollama.com/library
https://mistral.ai/news/mixtral-of-experts/
https://erichartford.com/uncensored-models
https://github.com/ollama/ollama

curl -fsSL https://ollama.com/install.sh | sh
ollama serve
ollama pull llama3.1:latest
ollama list
ollama run llama3.1:latest
ollama run gemma:2b

sudo docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data -name open-webui -restart always ghcr.io/open-webui/open-webui:ollama


mistral
https://mistral.ai/news/mixtral-of-experts/




dolphin-llama
https://ollama.com/hillct/dolphin-llama-3.1
https://huggingface.co/cognitivecomputations/dolphin-2.9.4-llama3.1-8b
https://www.promptlayer.com/models/dolphin-294-llama31-8b-3ac7
https://ollama.com/CognitiveComputations/dolphin-llama3.1:latest/blobs/c4e04968e3ca
https://huggingface.co/llmware/dolphin-2.9.4-llama3.1-8b-ov
https://github.com/ggerganov/llama.cpp/issues/8895

ollama pull rjmalagon/dolphin-2.9.4-llama3.1-8b:q8_0



cpu
ollama run llama2:13b
ollama run llama3:8b
ollama run mistral:7b
ollama run gemma2:9b
ollama run llava:9b
ollama run phi3:3.8b
ollama run gwen2:7b



#####################################################
LM Studio
#####################################################
https://www.youtube.com/watch?v=KtSdNwVkpWc

https://lmstudio.ai/
LM_Studio-0.3.5.AppImage
https://lmstudio.ai/docs


#####################################################
Open WebUI Channels : v0.5.3 Complete Guide
#####################################################

https://www.youtube.com/watch?v=pfxxZ7rQUJg

docker run -d -p 3000:8080 --env ENABLE_CHANNELS=true --env ENABLE_ADMIN_CHAT_ACCESS=true --env BYPASS_MODEL_ACCESS_CONTROL=true -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main


#####################################################
Desktop LLMs
#####################################################

https://anythingllm.com/desktop
https://docs.anythingllm.com/installation-desktop/linux#install-using-the-installer-script

#####################################################
Run LLMs locally - 5 Must-Know Frameworks
#####################################################

https://www.youtube.com/watch?v=5WCvGyPpWwg
Ollama
GPT4All
PrivateGPT
llama.cpp
LangChain


#####################################################
Best ChatGPT Alternatives for Everyday Use
#####################################################

https://www.youtube.com/watch?v=wwcneSVMK-A

https://www.meta.ai/
https://pi.ai/
https://copilot.microsoft.com/
https://www.phind.com/search
https://huggingface.co/cognitivecompu...
https://chat.mistral.ai/
https://poe.com/
https://gemini.google.com/
https://thegigabrain.com/
https://blogs.microsoft.com/blog/2023...
https://character.ai/
https://aistudio.google.com/app
https://chatgpt.com/
https://claude.ai/
https://www.perplexity.ai/


#####################################################
The Self-hosted AI Starter Kit
#####################################################

https://github.com/n8n-io/self-hosted-ai-starter-kit
https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/
https://github.com/n8n-io/self-hosted-ai-starter-kit/blob/main/docker-compose.yml
https://hub.docker.com/r/localai/localai
https://hub.docker.com/r/elestio/flowiseai
https://community.n8n.io/c/tutorials/28

https://github.com/coleam00/ai-agents-masterclass/tree/main/local-ai-packaged
https://github.com/n8n-io/self-hosted-ai-starter-kit


#####################################################
LLM Everywhere: Docker for Local and Hugging Face Hosting
#####################################################

https://hub.docker.com/
https://www.docker.com/blog/llm-docker-for-local-and-hugging-face-hosting/
https://hub.docker.com/r/ollama/ollama

https://hub.docker.com/r/pytorch/pytorch
https://hub.docker.com/r/tensorflow/tensorflow


#####################################################
Pinokio AI Browser
#####################################################

https://www.youtube.com/watch?v=A1qzxDxfMZQ

https://pinokio.computer/

https://pinokio.computer/item?uri=https://github.com/pinokiofactory/MMAudio
https://pinokio.computer/item?uri=https://github.com/pinokiofactory/ai-video-composer
https://pinokio.computer/item?uri=https://github.com/pinokiofactory/comfy
https://pinokio.computer/item?uri=https://github.com/pinokiofactory/open-webui
https://pinokio.computer/item?uri=https://github.com/pinokiofactory/whisper-webui
https://pinokio.computer/item?uri=https://github.com/pinokiofactory/hallo
https://pinokio.computer/item?uri=https://github.com/pinokiofactory/stableaudio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/openvoice2
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/customnet
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/differential-diffusion-ui
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/chatbot-ollama
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/automatic1111
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/sdxl-turbo
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/diffusers-sdxl-turbo
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/svd.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/illusion.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/audio-webui.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/AudioLDM2.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/audiogradio.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/animatediff.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/llamacpp.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/tutorial.pinokio
https://pinokio.computer/item?uri=https://github.com/SUP3RMASS1VE/SD-Next
https://pinokio.computer/item?uri=https://github.com/6Morpheus6/illusion-diffusion-HQ
https://pinokio.computer/item?uri=https://github.com/tazztone/whisper-large-v3


###########################################
Pinokio
###########################################

https://pinokio.computer/
https://program.pinokio.computer/#/?id=install
https://program.pinokio.computer/#/?id=linux
https://github.com/pinokiocomputer/pinokio/releases/tag/1.3.4
https://github.com/pinokiocomputer/pinokio/releases/download/1.3.4/Pinokio_1.3.4_arm64.deb

https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/fooocus
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/differential-diffusion-ui
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/open-webui
https://pinokio.computer/item?uri=https://github.com/facefusion/facefusion-pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/magnet
https://pinokio.computer/item?uri=https://github.com/cocktailpeanutlabs/automatic1111
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/sdxl-turbo
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/svd.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/audiocraft_plus.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/audio-webui.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/audiogradio.pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/tutorial.pinokio
https://pinokio.computer/item?uri=https://github.com/6Morpheus6/pinokio-wiki
https://pinokio.computer/item?uri=https://github.com/facefusion/facefusion-pinokio
https://pinokio.computer/item?uri=https://github.com/Feedjer/stable-diffusion-webui-ux.pinokio
https://pinokio.computer/item?uri=https://github.com/supersonic13/sdxs-pinokio
https://pinokio.computer/item?uri=https://github.com/cocktailpeanut/AudioLDM2.pinokio


#####################################################
8 AI Tools
#####################################################

Napkin AI - https://www.napkin.ai/
NotebookLM - https://notebooklm.google.com/
Pinokio - https://pinokio.computer/
Replicate - https://replicate.com/
Flux Dev Lora Trainer - https://replicate.com/ostris/flux-dev...
Spotter Studio - https://partner.spotterstudio.com/fut...
Guidde - https://www.guidde.com/
Suno - https://suno.com/


#####################################################
Open NoteBookLM
#####################################################

https://www.youtube.com/watch?v=M3wue0dw6tw
https://github.com/gabrielchua/open-notebooklm/tree/main

git clone https://github.com/gabrielchua/open-notebooklm.git
cd open-notebooklm

python -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt

python app.py

#####################################################
PodCastfy
#####################################################

https://www.youtube.com/watch?v=q26rqFg--84

https://github.com/souzatharsis/podcastfy
https://github.com/souzatharsis/podcastfy-demo

pip install ffmpeg
pip install podcastfy
Set up your API keys

from podcastfy.client import generate_podcast

audio_file = generate_podcast(urls=["<url1>", "<url2>"])
python -m podcastfy.client --url <url1> --url <url2>




#####################################################
#####################################################
https://scalastic.io/en/mixtral-ollama-llamaindex-llm/
https://peterfalkingham.com/2024/04/26/my-experience-training-a-local-llm-ai-chatbot-on-local-data/

chatDocs
privateGPT
phi-1
TinyStories
GPT4All
OPENAI
Lora
Ollama
FAST- GPT-LLM-Trainer



ollama run mixtral
conda create --name mixtral_ollama python=3.11
conda activate mixtral_ollama
# llama-index
pip install -r requirements.txt
python reference_test.py



#####################################################
FemtoGPT
#####################################################

https://www.youtube.com/watch?v=jEyPQUyNhD0
https://github.com/keyvank/femtoGPT
https://github.com/cthiriet/femtoGPT
https://docs.rs/femto-gpt/latest/femto_gpt/
https://crates.io/crates/femto-gpt/reverse_dependencies



#####################################################
LLMs locally
#####################################################

pip install llm
llm install llm-gpt4all
llm -m the-model-name "Your query"
llm -m ggml-model-gpt4all-falcon-q4_0 "Tell me a joke about computer programming"
llm aliases set falcon ggml-model-gpt4all-falcon-q4_0


https://github.com/ollama/ollama
https://scalastic.io/en/mixtral-ollama-llamaindex-llm/
https://www.restack.io/p/llm-orchestration-answer-train-own-data-cat-ai

ollama run model-name


h2oGPT
PrivateGPT

#####################################################
llamafile
#####################################################

https://github.com/Mozilla-Ocho/llamafile

curl -L https://github.com/Mozilla-Ocho/llamafile/releases/download/0.1/llamafile-server-0.1 > llamafile
chmod +x llamafile

./llamafile --model ./zephyr-7b-alpha.Q4_0.gguf
http://127.0.0.1:8080.

 GitHub repository: mistral-7b-instruct, llava-v1.5-7b-server, or wizardcoder-python-13b.

#####################################################
LocalGPT
#####################################################

https://github.com/PromtEngineer/localGPT
https://www.youtube.com/watch?v=MlyoObdIHyo

LM Studio
https://lmstudio.ai/
https://huggingface.co/models
https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html
https://huggingface.co/docs/trl/en/learning_tools


#####################################################
LLMs can be used to label data and support analyses.
#####################################################

https://github.com/thu-vu92/local-llms-analyse-finance#
https://www.youtube.com/watch?v=h_GTxRFYETY