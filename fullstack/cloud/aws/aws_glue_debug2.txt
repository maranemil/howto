##################################################################################
ctypes import
##################################################################################

https://docs.aws.amazon.com/batch/latest/userguide/Batch_GetStarted.html
https://stackoverflow.com/questions/57598027/connection-with-oracle-cx-oracle-problem-with-aws-glue-python-shell
https://pavan-andhukuri.medium.com/connecting-to-oracle-database-from-aws-glue-python-shell-not-possible-168cba968da9
https://www.appsloveworld.com/oracle/100/74/unable-to-connect-oracle-database-using-cx-oracle-from-aws-glue
https://stackoverflow.com/questions/57598027/connection-with-oracle-cx-oracle-problem-with-aws-glue-python-shell/59467059#59467059
https://stackoverflow.com/questions/10619298/libaio-so-1-cannot-open-shared-object-file/53981971#53981971
https://www.appsloveworld.com/oracle/100/77/amazon-python-2-7-lambda-dpi-1047-64-bit-oracle-client-library-cannot-be-loaded
https://splunktool.com/connection-with-oracle-cxoracle-problem-with-aws-glue-python-shell
https://www.pnpsummit.com/show-question/1171562/connection-with-oracle-cx_oracle-problem-with-aws-glue-python-shell
https://github.com/oracle/python-cx_Oracle/issues/612
https://github.com/oracle/python-cx_Oracle/issues/319

from ctypes import *
cdll.LoadLibrary('<absolute_path_to_library_dir>/libclntsh.so')


https://kandi.openweaver.com/c/Bluehorn/cx_Oracle#Code-Snippets

import ctypes
from ctypes import util
print(ctypes.util.find_library('cap.so'))

from ctypes import cdll
cdll.LoadLibrary('oci.dll')

-------

https://note.nkmk.me/en/python-os-getcwd-chdir/
https://java2blog.com/print-current-directory-python/

import os
path = os.getcwd()
print(path)

import os
print(os.getcwd())

-------

https://carpentries-incubator.github.io/lesson-parallel-python/08-calling_external_C_libraries/index.html

%import ctypes
%testlib = ctypes.cdll.LoadLibrary("./libtest.so")
%sum_range = testlib.sum_range
%sum_range.argtypes = [ctypes.c_longlong]
%sum_range.restype = ctypes.c_longlong
%high=1000000000
%brute_force_sum=sum_range(high)

-------

import os
import sys
print(sys.version)
print(os.environ)

import platform
print(platform.architecture()) # ('64bit', 'ELF')

print("FILES AT LOCATION:")
for name in os.listdir('/home'):
    print(name)



SO files often reside in the following Linux directories:
/lib
/usr/lib
/usr/local/lib
/usr/lib/modules
/usr/lib/oracle/21/client64/lib/


import cx_Oracle
import os
import sys
print(sys.version)
#print(os.environ['ORACLE_HOME'])
print(os.environ['path'])
con = cx_Oracle.connect('USER/pass@host:port/SID')
print (con.version)
con.close()


LOCATION = r"C:\Oracle\instantclient_18_5"
print("ARCH:", platform.architecture())
print("FILES AT LOCATION:")
for name in os.listdir(LOCATION):
    print(name)
os.environ["PATH"] = LOCATION + ";" + os.environ["PATH"]

import cx_Oracle
conn = cx_Oracle.connect("USER/pass@server/SERVICE")

##################################################################################
etl
##################################################################################

https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html#aws-glue-programming-etl-connect-jdbc
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect-samples.html
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-samples-legislators.html
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html#aws-glue-programming-etl-connect-jdbc
https://docs.aws.amazon.com/glue/latest/dg/connection-properties.html
https://docs.aws.amazon.com/glue/latest/dg/connection-properties.html
https://docs.aws.amazon.com/glue/latest/dg/glue-troubleshooting-errors.html
https://docs.aws.amazon.com/glue/latest/dg/crawler-data-stores.html
https://docs.aws.amazon.com/glue/latest/dg/glue-connections.html
https://docs.aws.amazon.com/glue/latest/ug/connectors-chapter.html
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-jobs-job.html
https://aws.amazon.com/blogs/big-data/aws-glue-python-shell-now-supports-python-3-9-with-a-flexible-pre-loaded-environment-and-support-to-install-additional-libraries/
https://github.com/awslabs/aws-glue-libs
https://aws.amazon.com/premiumsupport/knowledge-center/glue-import-error-no-module-named/
https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-magics.html
https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-libraries.html
https://docs.aws.amazon.com/de_de/glue/latest/dg/aws-glue-programming-python-libraries.html
https://github.com/aws/aws-cdk/issues/20481
https://stackoverflow.com/questions/73811842/managing-aws-secrets-manager-in-aws-glue
https://aws.plainenglish.io/understanding-all-aws-glue-import-statements-and-why-we-need-them-59279c402224
https://splunktool.com/connection-with-oracle-cxoracle-problem-with-aws-glue-python-shell
https://catalog.us-east-1.prod.workshops.aws/workshops/ee59d21b-4cb8-4b3d-a629-24537cf37bb5/en-US/lab2/etl-code

For JDBC, MongoDB, and Amazon DocumentDB (with MongoDB compatibility) data stores, you must specify an AWS Glue connection that the crawler can use to connect to the data store.
For Amazon S3, you can optionally specify a connection of type Network. A connection is a Data Catalog object that stores connection information, such as credentials,
URL, Amazon Virtual Private Cloud information, and more. For more information, see Defining connections in the AWS Glue Data Catalog.

To test a connection, you must use the Connections (legacy) page in the AWS Glue console. AWS Glue Studio does not currently support testing a connection.

import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext, SparkConf
from awsglue.context import GlueContext
from awsglue.job import Job
import time
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session


connection_oracle_options = {
    "url": "jdbc:oracle:thin:@//<jdbc-host-name>:1521/ORCL",
    "dbtable": "test",
    "user": "admin",
    "password": "pwd"}


df_oracle = glueContext.create_dynamic_frame.from_options(connection_type="oracle",
                                                            connection_options=connection_oracle_options)


##################################################################################
How do I use external Python libraries in my AWS Glue 2.0 ETL job?
##################################################################################

https://aws.amazon.com/premiumsupport/knowledge-center/glue-version2-external-python-libraries/
https://aws.amazon.com/premiumsupport/knowledge-center/glue-job-use-external-python-libraries/


Open the AWS Glue console.
Choose Jobs.
Select the job where you want to add the Python module.
Choose Actions, and then choose Edit job.
Expand the Security configuration, script libraries, and job parameters (optional) section.

Under Job parameters, do the following:
For Key, enter --additional-python-modules.
For Value, enter pymysql==1.0.2, s3://aws-glue-add-modules/nltk-3.6.2-py3-none-any.whl.
Choose Save.

or

Launch an Amazon Elastic Compute Cloud (Amazon EC2) Linux instance with enough volume space for your libraries.
Install Docker container on the instance, set up the non-sudo access, and then start docker.

sudo yum install docker -y
sudo usermod -a -G docker ec2-user
sudo service docker start


Create a file dockerfile_grpcio and copy the following into the file:

# Base for AWS Glue
FROM amazonlinux
RUN yum update -y
RUN yum install shadow-utils.x86_64 -y
RUN yum install -y java-1.8.0-openjdk.x86_64
RUN yum install -y python3
RUN yum install -y cython doxygen numpy scipy gcc autoconf automake libtool zlib-devel openssl-devel maven wget protobuf-compiler cmake make gcc-c++
# Additional components needed for grpcio
WORKDIR /root
RUN yum install python3-devel -y
RUN yum install python-devel -y
RUN pip3 install wheel
# Install grpcio and related modules
RUN pip3 install Cython
RUN pip3 install cmake scikit-build
RUN pip3 install grpcio
# Create a directory for the wheel
RUN mkdir wheel_dir
# Create the wheel
RUN pip3 wheel grpcio -w wheel_dir


Run the docker build to build your Dockerfile. Run the following commands to restart the Docker daemon:

$ sudo service docker restart
$ docker build -f dockerfile_grpcio .

Extract the wheel file from the Docker container. Run the following commands to extract the .whl file:

# Get the docker image ID
$ docker image ls

# Run the container
$ docker run -dit 111122223334444

# Verify the location of the wheel file and retrieve the name of the wheel file
$ docker exec -t -i 5555666677778888 ls /root/wheel_dir/

# Copy the wheel out of docker to EC2
$ docker cp 5555666677778888:/root/wheel_dir/doc-example-wheel .


Be sure to replace the following values in the preceding commands:

1111222233334444 with the Docker image ID
5555666677778888 with the container ID
doc-example-wheel with the name of the generated wheel file
6.    Upload the wheel to Amazon S3 by running the following commands:

aws s3 cp doc-example-wheel s3://path/to/wheel/
aws s3 cp grpcio-1.32.0-cp37-cp37m-linux_x86_64.whl s3://aws-glue-add-modules/grpcio/


Be sure to replace the following values in the preceding commands:

doc-example-wheel with the name of the generated wheel file
grpcio-1.32.0-cp37-cp37m-linux_x86_64.whl with the name of the Python package file
7.    For the AWS Glue ETL job, in the AWS Glue console, under Job parameters, do the following: For Key, enter --additional-python-modules.
For Value, enter s3://aws-glue-add-modules/grpcio/grpcio-1.32.0-cp37-cp37m-linux_x86_64.whl.
Note: Be sure to replace grpcio-1.32.0-cp37-cp37m-linux_x86_64.whl with the name of the Python package file.




##################################################################################
check  host
##################################################################################

nslookup hostname
dig hostname

##################################################################################
Install the PDO Oracle OCI Extension
##################################################################################

https://docwiki.embarcadero.com/HTML5_Builder/en/Oracle_on_a_Ubuntu_Server

apt-get install php5-dev
apt-get install libaio libaio-dev
pecl install oci8

php --ri oci8


##################################################################################
DatabaseError: DPI-1047: Cannot locate a 64-bit Oracle Client library: libclntsh.so
##################################################################################

https://stackoverflow.com/questions/57598027/connection-with-oracle-cx-oracle-problem-with-aws-glue-python-shell
https://www.oracle.com/de/database/technologies/instant-client/linux-x86-64-downloads.html
https://www.ibm.com/support/pages/how-query-oracle-data-source-using-db2-federation-through-oracle-instant-client
https://www.ibm.com/support/pages/federation-oracle-database-using-odbc-or-oracle-instant-client

https://www.oracle.com/de/database/technologies/instant-client/linux-x86-64-downloads.html
wget https://download.oracle.com/otn_software/linux/instantclient/218000/instantclient-basic-linux.x64-21.8.0.0.0dbru.zip
wget https://download.oracle.com/otn_software/linux/instantclient/218000/instantclient-basiclite-linux.x64-21.8.0.0.0dbru.zip
unzip instantclient-basic-linux.x64-21.8.0.0.0dbru.zip




As it has already been mentioned in the responses. LD_LIBRARY_PATH needs to be set before the script starts. So, a way to avoid using LD_LIBRARY_PATH is setting rpath in the so file. Below are the steps needed.

You will need to update rpath in your so file. This can be done using patchelf package.

Please also include your libaio.so.1 in your so files which you might have generated by running sudo apt-get install libaio1

Installing patchelf

sudo apt-get update
sudo apt-get install patchelf

To update rpath to your lib directory

patchelf --set-rpath <absolute_path_to_library_dir> libclntsh.so

Upload the so files with updated rpath to your glue env lib directory.

In your script you can then load the library.

from ctypes import *
cdll.LoadLibrary('<absolute_path_to_library_dir>/libclntsh.so')



https://www.programcreek.com/python/example/92493/ctypes.util.find_library
https://stackoverflow.com/questions/59083051/how-to-use-ctypes-util-find-library-to-import-so-libraries-in-aws-lambda-pytho
https://docs.python.org/3/library/ctypes.html

ctypes.util.find_library(name)


import ctypes
from ctypes import util
print(ctypes.util.find_library('libclntsh')) # None
print(ctypes.util.find_library('crypto')) # libcrypto.so.10
print(ctypes.util.find_library('cap')) # libcap.so.2

##################################################################################
check if a key exists in a bucket in s3 using boto3
##################################################################################
https://stackoverflow.com/questions/33842944/check-if-a-key-exists-in-a-bucket-in-s3-using-boto3
https://www.peterbe.com/plog/fastest-way-to-find-out-if-a-file-exists-in-s3

import boto3
import botocore

s3 = boto3.resource('s3')

try:
    s3.Object('my-bucket', 'dootdoot.jpg').load()
except botocore.exceptions.ClientError as e:
    if e.response['Error']['Code'] == "404":
        # The object does not exist.
        ...
    else:
        # Something else has gone wrong.
        raise
else:
    # The object does exist.
    ...


##################################################################################
How to save S3 object to a file using boto3
##################################################################################

https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3
https://www.learnaws.org/2022/07/02/boto3-download-files-s3/
https://www.stackvidhya.com/download-files-from-s3-using-boto3/
https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html
https://www.geeksforgeeks.org/python-os-path-isfile-method/

import boto3
import botocore
import os

s3_client = boto3.client('s3')
s3_client.download_file('test-libs', 'cap.so', 'cap.so')
if(os.path.isfile('cap.so')):
    print('file succesfully downloaded locally')


import shutil
shutil.copyfile('cap.so', '/usr/lib64/cap.so')

PermissionError: [Errno 13] Permission denied: '/usr/lib64/cap.so'

for name in os.listdir('/usr/lib64'):
    print(name)


print(os.listdir('/usr/lib64'))

---------


s3_client = boto3.client('s3')
open('hello.txt').write('Hello, world!')

# Upload the file to S3
s3_client.upload_file('hello.txt', 'MyBucket', 'hello-remote.txt')

# Download the file from S3
s3_client.download_file('MyBucket', 'hello-remote.txt', 'hello2.txt')
print(open('hello2.txt').read())


----

resource = boto3.resource('s3')
my_bucket = resource.Bucket('MyBucket')
my_bucket.download_file(key, local_filename)


##################################################################################
check so libs
##################################################################################

https://gist.github.com/gene1wood/4a052f39490fae00e0c3

for name in os.listdir('/usr/lib64'):
    print(name)


libp11-kit.so.0
libdb-5.3.so
libkeyutils.so.1
libkrb5.so.3.3
libuuid.so.1
libmenuw.so.6
librpmio.so.3
libssl.so.1.0.2k
libanl-2.26.so
libgdbm_compat.so.4

...


##################################################################################
Oracleâ€™s Instant Client 12.1 and Oracle SQL Plus on Ubuntu
##################################################################################

https://www.lisenet.com/2014/install-oracles-instant-client-12-1-and-oracle-sql-plus-on-ubuntu-12-04-x64/
https://cx-oracle.readthedocs.io/en/latest/user_guide/installation.html
https://www.oracle.com/de/database/technologies/instant-client/linux-x86-64-downloads.html


instantclient-basic-linux.x64-12.1.0.1.0.zip
instantclient-sqlplus-linux.x64-12.1.0.1.0.zip


##################################################################################
python unzip
##################################################################################

https://stackoverflow.com/questions/3451111/unzipping-files-in-python
https://www.geeksforgeeks.org/unzipping-files-in-python/
https://www.geeksforgeeks.org/python-unzip-a-list-of-tuples/


import zipfile
with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
    zip_ref.extractall(directory_to_extract_to)


import zipfile
with zipfile.ZipFile("file.zip","r") as zip_ref:
    zip_ref.extractall("targetdir")

##################################################################################
oracle linux client
##################################################################################

https://www.oracle.com/it/database/technologies/instant-client/linux-x86-64-downloads.html
https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html
https://yum.oracle.com/oracle-linux-nodejs.html
https://github.com/oracle/node-oracledb/issues/1059
https://yum.oracle.com/oracle-linux-nodejs.html
https://www.oracle.com/database/technologies/instant-client/downloads.html

##################################################################################
makedirs
##################################################################################

https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory
https://thispointer.com/how-to-create-a-directory-in-python/
https://www.geeksforgeeks.org/create-a-directory-in-python/

import os
if not os.path.exists(directory):
    os.makedirs(directory)

##################################################################################
AWS Glue JDBC connection properties
##################################################################################

https://docs.aws.amazon.com/glue/latest/dg/connection-properties.html#connection-properties-jdbc
https://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html
https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html
https://github.com/aws-samples/aws-lambda-python-oracle-connection
https://aws.plainenglish.io/connect-to-oracle-rds-instance-from-a-lambda-function-902a9a297741
https://docs.aws.amazon.com/lambda/latest/dg/configuration-database.html
https://docs.aws.amazon.com/glue/latest/dg/migrating-version-40.html
https://www.oracle.com/database/technologies/appdev/jdbc-downloads.html
https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.html


Currently, an ETL job can use JDBC connections within only one subnet. If you have multiple data stores in a job, they must be on the same subnet.

Driver
Oracle Databases

JDBC driver version in past AWS Glue versions   11.2
JDBC driver version in AWS Glue 3.0	            21.1
JDBC driver version in AWS Glue 4.0             21.7


https://aws.amazon.com/blogs/big-data/building-aws-glue-spark-etl-jobs-by-bringing-your-own-jdbc-drivers-for-amazon-rds/
https://www.oracle.com/database/technologies/appdev/jdbc-downloads.html
https://medium.com/nerd-for-tech/export-oracle-database-to-postgresql-using-aws-glue-551860965c58

https://download.oracle.com/otn-pub/otn_software/jdbc/217/ojdbc11.jar
https://download.oracle.com/otn-pub/otn_software/jdbc/217/ojdbc8.jar
https://download.oracle.com/otn-pub/otn_software/jdbc/1916/ojdbc10.jar
https://download.oracle.com/otn-pub/otn_software/jdbc/1815/ojdbc8.jar


https://repost.aws/questions/QUiuKF71nASHmc5IlGGgmmTA/how-to-connect-on-premise-oracle-database-from-glue-without-using-crawler
https://repost.aws/questions/QU74cjzPDLRE2FZy12yjmBGA/aws-glue-connect-with-on-premise-db
https://repost.aws/questions/QUiuKF71nASHmc5IlGGgmmTA/how-to-connect-on-premise-oracle-database-from-glue-without-using-crawler
https://repost.aws/questions/QU3H23qpWyRQCkNcuDc_yx6A/how-to-connect-to-oracle-on-premise-from-aws-dms

https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.VPC.html#CHAP_ReplicationInstance.VPC.Configurations.ScenarioInternet
https://aws.amazon.com/blogs/awsforsap/extracting-data-from-sap-hana-using-aws-glue-and-jdbc/
https://aws.amazon.com/blogs/big-data/building-aws-glue-spark-etl-jobs-by-bringing-your-own-jdbc-drivers-for-amazon-rds/

Can we connect to database directly either using spark read or dynamic_frame_from_options by passing DB details ?

Ans:- Provided that you attach a new or existing JDBC connection to the Glue job, you can connect to the database directly. The JDBC connection shall contain the details about your on-premise Oracle database along with the VPC and other details that are to be used by the Glue job. Again, if you want to use dynamic_frame_from_options then Glue catalog must be present.






