------------------------------------------------------------

python_lambda

https://www.w3schools.com/python/python_lambda.asp
https://www.geeksforgeeks.org/python-lambda-anonymous-functions-filter-map-reduce

------------------------------------------------------------

####################################################
delete object
####################################################

https://www.toppr.com/guides/python/methods-and-functions/del/python-del-statement-with-examples/

del obj_name[optional]

------------------------------------------------------------
####################################################
check file
####################################################

https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists-without-exceptions

import os

if os.path.isfile(filepath):
   print("File exists")


####################################################
How to compare lists in Python
####################################################

https://java2blog.com/python-compare-lists/
https://www.tutorialspoint.com/find-mismatch-item-on-same-index-in-two-list-in-python
https://www.digitalocean.com/community/tutorials/how-to-compare-two-lists-in-python
https://www.w3resource.com/python-exercises/list/python-data-type-list-exercise-198.php

import functools
l1 = [10, 20, 30, 40, 50]
l2 = [10, 20, 30, 50, 40, 70]
l3 = [10, 20, 30, 40, 50]
if functools.reduce(lambda x, y : x and y, map(lambda p, q: p == q,l1,l2), True):
    print ("The lists l1 and l2 are the same")
else:
    print ("The lists l1 and l2 are not the same")
if functools.reduce(lambda x, y : x and y, map(lambda p, q: p == q,l1,l3), True):
    print ("The lists l1 and l3 are the same")
else:
    print ("The lists l1 and l3 are not the same")


import collections
l1 = [10, 20, 30, 40, 50]
l2 = [10, 20, 30, 50, 40, 70]
l3 = [10, 20, 30, 40, 50]
if collections.Counter(l1) == collections.Counter(l2):
    print ("The lists l1 and l2 are the same")
else:
    print ("The lists l1 and l2 are not the same")
if collections.Counter(l1) == collections.Counter(l3):
    print ("The lists l1 and l3 are the same")
else:
    print ("The lists l1 and l3 are not the same")



l1 = [10, 20, 30, 40, 50]
l3 = [50, 10, 30, 20, 40]
a = set(l1)
b = set(l3)
if a == b:
    print("Lists l1 and l3 are equal")
else:
    print("Lists l1 and l3 are not equal")




l1 = [10, 20, 30, 40, 50]
l3 = [50, 75, 30, 20, 40, 69]
res = [x for x in l1 + l3 if x not in l1 or x not in l3]
print(res)
if not res:
    print("Lists l1 and l3 are equal")
else:
    print("Lists l1 and l3 are not equal")


# With zip
listA= [13, 'Mon',23, 62,'Sun']
listB = [5, 'Mon',23, 6,'Sun']
#res = [listB.index(n) for m, n in zip(listA, listB) if n != m]
res = [listB.index(m) for m, n in zip(listA, listB) if n != m]
print("The index positions with mismatched values:\n",res)


# With enumerate
listA= [13, 'Mon',23, 62,'Sun']
listB = [5, 'Mon',23, 6,'Sun']
res = [idx for idx, elem in enumerate(listB)
			if elem != listA[idx]]
print("The index positions with mismatched values:\n",res)



list1, list2 = ["a", "b", "c", "d", "e"], ["e", "d", "c", "b", "a"]
print [index for index, (e1, e2) in enumerate(zip(list1, list2)) if e1 == e2]
print(a==b)

a = [1,5,9]
b = [5,9,1]
print(set(a) == set(b))


a = [1,5,9]
b = [5,9,1]
d = (set(a) - set(b))
if len(d)==0:
    print("Equal")
else:
    print("Not Equal")



import functools
a = [1,5,9]
b = [5,9,1]
a.sort()
b.sort()
if functools.reduce(lambda h, k: h and k, map(lambda x, y: x == y, a, b), True):
    print("Equal")
else:
    print("Unequal")


####################################################
pyarrow fastparquet
####################################################

https://fixexception.com/pandas/engine-must-be-one-of-pyarrow-fastparquet/

pip install pyarrow
pip install fastparquet

if engine == "pyarrow":
return PyArrowImpl()
elif engine == "fastparquet":
return FastParquetImpl()
raise ValueError("engine must be one of 'pyarrow', 'fastparquet'")


import pandas as pd
df = pd.DataFrame({'a':[1,3,4,5],'b':[5,1,3,6]})
#Save DataFrame to parquet format
df.to_parquet('small.csv','pyarrow')

-----------------------------------------------------------

https://arrow.apache.org/docs/python/parquet.html
https://docs.dask.org/en/stable/dataframe-create.html
https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html
https://www.geeksforgeeks.org/how-to-create-an-empty-pyspark-dataframe/

-----------------------------------------------------------

#############################################################
object of type <class 'str'> cannot be converted to int
#############################################################

https://arrow.apache.org/docs/cpp/parquet.html#encodings
https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetWriter.html
https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetWriter.html
https://www.appsloveworld.com/pandas/100/6/error-converting-object-string-to-int32-typeerror-object-cannot-be-converted
https://pandas.pydata.org/pandas-docs/version/0.24/reference/api/pandas.Series.replace.html
https://www.programcreek.com/java-api-examples/?api=org.apache.parquet.column.Encoding


pyarrow.lib.ArrowTypeError: object of type <class 'str'> cannot be converted to int

schema = pa.schema([
  ('id', pa.int32()),
  ('message_id', pa.string()),
  ('transaction_id', pa.string()),
])


df.column = df.column.str.strip()
df.column = df.column.astype('float')  # first convert to float before int
df.column = df.column.astype('Int32')
df.column = df.column.astype('float').astype('Int32') # or Int64


Physical type	Mapped Arrow type

BOOLEAN		Boolean
INT32		Int32 / other
INT64		Int64 / other
INT96		Timestamp (nanoseconds)
FLOAT		Float32
DOUBLE		float64
BYTE_ARRAY	Binary / other




import pandas as pd
import json
from google.cloud import bigquery
cols_name_list = [....]. # column name in order
uri = "<csv_file>"
df = pd.read_csv(uri, dtype="string")
# df = pd.read_csv(uri, dtype={"B" : "string"})
df = df.reindex(columns=cols_name_list)
client = bigquery.Client()
job_config = bigquery.LoadJobConfig(
    schema = [
        bigquery.SchemaField("A", "INTEGER"),
        bigquery.SchemaField("B", "STRING"),
        bigquery.SchemaField("C", "INTEGER"),
        bigquery.SchemaField("D", "INTEGER"),
        bigquery.SchemaField("E", "DATETIME"),
        bigquery.SchemaField("F", "INTEGER"),
        bigquery.SchemaField("G", "DATETIME")
    ]
)
job = client.load_table_from_dataframe(
    df, "<bq_table_id>", job_config=job_config
)
job.result()


https://stackoverflow.com/questions/73346141/python-not-recognizing-list-of-dictionaries
https://stackoverflow.com/questions/47113813/using-pyarrow-how-do-you-append-to-parquet-file
https://github.com/googleapis/python-bigquery/issues/22
https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetWriter.html

import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq


chunksize=10000 # this is the number of lines
pqwriter = None
for i, df in enumerate(pd.read_csv('sample.csv', chunksize=chunksize)):
    table = pa.Table.from_pandas(df)
    # for the first chunk of records
    if i == 0:
        # create a parquet write object giving it an output file
        pqwriter = pq.ParquetWriter('sample.parquet', table.schema)
    pqwriter.write_table(table)
# close the parquet writer
if pqwriter:
    pqwriter.close()


https://github.com/googleapis/python-bigquery/issues/22

import pandas as pd
from google.cloud import bigquery

print(pd.__version__)
print(bigquery.__version__)

df = pd.DataFrame({'x': [1, 2, None, 4]})

df['x'] = df['x'].astype('Int64')
print(df.dtypes)

client = bigquery.Client()
dataset_ref = client.dataset('test_dataset')
table_ref = dataset_ref.table('test')

# ArrowTypeError: ('Did not pass numpy.dtype object', 'Conversion failed for column x with type Int64')

https://stackoverflow.com/questions/70449936/writing-pandas-dataframe-to-parquet-file
https://pandas.pydata.org/pandas-docs/version/1.0.1/reference/api/pandas.arrays.StringArray.html

query = f'select * from `{table["table_name"]}`'
for i,chunk in enumerate(pd.read_sql_query(query , conn, chunksize=10000)):

    all_columns = list(chunk) # Creates list of all column headers
    chunk[all_columns] = chunk[all_columns].astype(str)
    #convert data to string

    table_schema =chunk.dtypes.astype(str).to_dict()
    for k,v in table_schema.items():
        if v == 'object':
            table_schema[k]=pa.string()
    #create pyarrow schema for string format
    fields = [pa.field(x, y) for x, y in table_schema.items()]
    new_schema = pa.schema(fields)

    if i == 0:
        pqwriter = pq.ParquetWriter(where=updated_path,schema=new_schema, compression='snappy')

    table = pa.Table.from_pandas(df=chunk, schema=new_schema,preserve_index=False,safe=False)
    pqwriter.write_table(table)

client.load_table_from_dataframe(df, table_ref).result()

-------------------------------------------------------------------------------


###############################################################
python Enum
###############################################################

https://www.w3resource.com/python-exercises/data-structures-and-algorithms/python-data-structure-exercise-2.php
https://stackoverflow.com/questions/25982212/iterate-enum-in-definition-order-in-python-2
https://docs.python.org/3/library/enum.html
https://ispycode.com/Python/Files-and-directories/Modules/Enumerations-(enum)/Iterating-Over-Enums
https://ispycode.com/Python/Files-and-directories/Modules/Enumerations-(enum)/Comparing-Enums

>>> from enum import Enum
>>> class Color(Enum):
...     RED = 1
...     GREEN = 2
...     BLUE = 3


from enum import Enum
class Country(Enum):
    Afghanistan = 93
    Albania = 355
    Algeria = 213
    Andorra = 376
    Angola = 244
    Antarctica = 672
for data in Country:
    print('{:15} = {}'.format(data.name, data.value))





from enum import Enum
>>> class Shake(Enum):
...     __order__ = 'vanilla chocolate cookies mint'
...     vanilla = 7
...     chocolate = 4
...     cookies = 9
...     mint = 3
...
>>> for s in Shake:
...     print(s)



import enum
class EXCHANGE(enum.Enum):
    __order__ = " EXCHANGE_NSE EXCHANGE_BSE EXCHANGE_NFO EXCHANGE_CDS EXCHANGE_BFO EXCHANGE_MCX EXCHANGE_BCD "
    EXCHANGE_NSE = "NSE"
    EXCHANGE_BSE = "BSE"
    EXCHANGE_NFO = "NFO"
    EXCHANGE_CDS = "CDS"
    EXCHANGE_BFO = "BFO"
    EXCHANGE_MCX = "MCX"
    EXCHANGE_BCD = "BCD"
if __name__ == "__main__":
    for ex in EXCHANGE:
        print(f"{ex.name} : {ex.value}")


https://www.programiz.com/python-programming/online-compiler/

from enum import Enum
class Day(Enum):
  sunday = 1
  monday = 2
  tuesday = 3
  wednesday = 4
  thursday =5
  friday = 6
  saturday = 7

for day in Day:
  print('{:9}: {}'.format(day.name, day.value))

print(([x.value for x in Day ]))
