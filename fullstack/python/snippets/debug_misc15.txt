################################################
How to find out the number of CPUs using python
################################################
https://stackoverflow.com/questions/1006289/how-to-find-out-the-number-of-cpus-using-python
https://www.geeksforgeeks.org/python-os-cpu_count-method/

import psutil
psutil.cpu_count()

import os
cpuCount = os.cpu_count()

import psutil
print(len(psutil.Process().cpu_affinity()))

....

import multiprocessing
multiprocessing.cpu_count()

#!/usr/bin/env python3
import multiprocessing
import os
print(multiprocessing.cpu_count())
print(os.cpu_count())
print(len(os.sched_getaffinity(0)))

------------------------------------------------------------------------------

https://docs.python.org/3/library/threading.html
https://www.python-kurs.eu/threads.php
https://www.pythontutorial.net/python-concurrency/python-threading/

import time
from threading import Thread
Thread(target=sleeper, args=(i,)).start()

------------------------------------------------------------------------------
################################################
count sql rows table
################################################

https://docs.sqlalchemy.org/en/14/core/connections.html
https://docs.sqlalchemy.org/en/13/core/connections.html
https://docs.sqlalchemy.org/en/14/tutorial/data_update.html

results = con.execute(f"SELECT *  FROM table").fetchall()
rows_count = len(results)
print(rows_count)

------------------------------------------------------------------------------
################################################
SQLite Query: Select, Where, LIMIT, OFFSET, Count, Group By
################################################

https://www.sqlitetutorial.net/sqlite-limit/
https://www.guru99.com/sqlite-query.html
https://stackoverflow.com/questions/3325515/sqlite-limit-offset-query

SELECT column_list FROM table LIMIT row_count OFFSET offset;
SELECT column_list FROM table LIMIT offset, row_count;
SELECT trackId, name FROM tracks LIMIT 10 OFFSET 10;
SELECT * FROM Students LIMIT 4,3;


LIMIT <skip>, <count>
LIMIT <count> OFFSET <skip>

long timeLimitOffset = 0;
long timeLimitComma = 0;
for (int i = 0; i < 100000; i++)
{
   //first version
   timeLimitOffset += SqlDuraction("Select * from table1  order by col1 LIMIT " + (i + 1) + " OFFSET " + (1001 - i) + "");
   // second version
   timeLimitComma += SqlDuraction("Select * from table1 order by col1 LIMIT " + (1001 - i) + " , " + (i + 1) + "");
}

################################################
multiprocessing threading
################################################

import multiprocessing
cpus_count = multiprocessing.cpu_count()

results = con.execute(f"SELECT *  FROM {table}").fetchall()
rows_pqt_count = len(results)
print(rows_pqt_count)

sub_count = round(rows_pqt_count / cpus_count)
print('rows_pqt_count', rows_pqt_count)
print('sub_count', sub_count)

import threading
for ki in range(1, cpus_count):
    print("proc" + str(ki))
    if ki == 8:
                time.sleep(120)
    threading.Thread(target=cls.writeSomething, args=(ki, arr1, arr2, sub_count,)).start()

exit()


################################################
How to set in pandas the first column and row as index?
################################################

https://replit.com/@Tyjch/Pandas-Playground
https://stackoverflow.com/questions/36606931/how-to-set-in-pandas-the-first-column-and-row-as-index
https://pythonexamples.org/pandas-set-column-as-index

df1 = pd.DataFrame({'a':[1,2,3,4,5], 'b':[6,7,8,9,0]})
df1
   a  b
0  1  6
1  2  7
2  3  8
3  4  9
4  5  0

df1 =  df1.set_index(['b'])
df1
   a
b
6  1
7  2
8  3
9  4
0  5

################################################
print only certain columns pandas”
################################################

https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe
https://www.codegrepper.com/code-examples/python/print+only+certain+columns+pandas
https://www.w3resource.com/python-exercises/pandas/python-pandas-data-frame-exercise-5.php
https://stackoverflow.com/questions/67713308/limit-pandas-loc-method-output-within-a-iloc-range
https://stackoverflow.com/questions/10202570/find-row-where-values-for-column-is-maximal-in-a-pandas-dataframe


print(df[['a', 'b']])
print(df.iloc[:, 0:19])
df = df[["Column_Name1", "Column_Name2"]]
dataframe.iloc[:,[1,2]]

df['Score'].iloc[430:440].max()].iloc[0]
df['Score'].iloc[430:440].idxmax()

df.loc[:, 'C':'E']
df[['C', 'D', 'E']]
df.loc[:, ['C', 'D', 'E']]



import pandas as pd
import numpy as np
np.random.seed(5)
df = pd.DataFrame(np.random.randint(100, size=(100, 6)),
                  columns=list('ABCDEF'),
                  index=['R{}'.format(i) for i in range(100)])
df.head()
df.loc[:, 'C':'E']
df.loc['R6':'R10', 'C':'E']
df.loc[:, df.columns.isin(list('BCD'))]
df.columns[2:4]
df.filter(['a', 'b'])

...

import pandas as pd
import numpy as np

exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],
        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],
        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],
        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}
labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']

df = pd.DataFrame(exam_data , index=labels)
print("Select specific columns:")
print(df[['name', 'score']])
...
from pandas import Series, DataFrame
s=Series([2,4,4,3],index=['a','b','c','d'])
s.idxmax()
s[s==s.max()]



import pandas
import numpy as np
df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])
df
df['A'].idxmax()
df['B'].idxmax()
df['C'].idxmax()

-------------------------------------------------------------

################################################
Pandas: convert dtype 'object' to int
ArrowTypeError: ("Expected bytes, got a 'float' object",
ArrowTypeError: ("Expected bytes, got a 'float' object", 'Conversion failed for column Pre-Rumour_Date with type object')
################################################

https://github.com/wesm/feather/issues/349
https://www.nbshare.io/notebook/188264382/Python-Pandas-String-To-Integer-And-Integer-To-String-DataFrame/
https://stackoverflow.com/questions/39173813/pandas-convert-dtype-object-to-int
https://stackoverflow.com/questions/68826636/pandas-to-parquet-file

import pandas as pd
df = pd.DataFrame({'column': ['asdf', u'uh ™ oh', 123]})
df['column'] = df['column'].astype('str')
df['column'] = df['column'].astype('unicode')
df['studentid'].astype('int',errors='ignore')
pd.to_numeric(df['studentid'],errors='coerce')


df = pd.DataFrame({
     'a': [1, 2, np.nan],
     'b': [True, False, np.nan]}, dtype=object)
df
df['a'].astype(str).astype(int) # raises ValueError
df.convert_dtypes()
df.convert_dtypes().dtypes

s = pd.Series(['1', '2', '...'])
s.convert_dtypes()  # converts to string, which is not what we want
pd.to_numeric(s, errors='coerce')
pd.to_numeric(s, errors='coerce').convert_dtypes()


import pandas as pd
testdf = pd.DataFrame({'testcol':['item1', 'item2', 3, 'item4']})
testdf.to_feather('testdf.feather')

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html
print(df.dtypes)
-------------------------------------------------------------

################################################
pyarrow.lib.ArrowInvalid:
('Could not convert X with type Y: did not recognize Python value type when inferring an Arrow data type')
Reading and writing Apache arrow files
################################################

https://stackoverflow.com/questions/59636745/pyarrow-lib-arrowinvalid-could-not-convert-x-with-type-y-did-not-recognize-p
https://www.anycodings.com/1questions/616378/pyarrowlibarrowinvalid-could-not-convert-x-with-type-y-did-not-recognize-python-value-type-when-inferring-an-arrow-data-type
https://awkward-array.org/how-to-convert-arrow.html
https://ittutorialpoint.com/pyarrow-lib-arrowinvalid-could-not-convert-x-with-type-y-did-not-recognize-python-value-type-when-inferring-an-arrow-data-type/


import pandas as pd
import pyarrow as pa
print("Reading arrow file...")
mmap = pa.memory_map('../data/sim_log_uncompressed.arrow')
with mmap as source:
    array = pa.ipc.open_file(source).read_all()


import pandas as pd
import pyarrow as pa
print("Reading arrow file...")
mmap = pa.memory_map('../data/sim_log_uncompressed.arrow')
with mmap as source:
    array = pa.ipc.open_file(source).read_all()
# print(array.schema)
# print(array[0]) # time, works
# print(array[1]) # orientation, works
# the following works, but you need one table per column
t_time   = pa.Table.from_arrays([array[0]], names=["time"])
t_orient = pa.Table.from_arrays([array[1]], names=["orient"])
# this gives just one table;
table = array.to_pandas()
print(table)

-------------------------------------------------------------
################################################
SQL-python aws
################################################

https://velog.io/@jua/Python-Connect-to-AWS-RDS-with-sqlalchemy-and-get-tables

from sqlalchemy import create_engine, Table, MetaData

url = "{AWS rds db url: postgresql://{user}:{password}@{rds endpoint}:{port}/{DB name}}"

engine = create_engine(url)
connect = engine.connect()
meta = MetaData()

table = Table(name='{table_name}',
              metadata=meta,
              autoload_with=connect,
              postgresql_ignore_search_path=True)

-------------------------------------------------------------

################################################
pyarrow Table
################################################

https://wesm.github.io/arrow-site-test/python/generated/pyarrow.Table.html
https://snyk.io/advisor/python/pyarrow/functions/pyarrow.Table.from_pandas
https://stackoverflow.com/questions/49565713/assign-schema-to-pa-table-from-pandas
https://arrow.apache.org/docs/7.0/python/generated/pyarrow.Table.html
https://arrow.apache.org/docs/python/generated/pyarrow.Table.html
https://stackoverflow.com/questions/56377848/writing-stream-of-big-data-to-parquet-with-python
https://github.com/apache/arrow/issues/8025
https://arrow.apache.org/docs/python/parquet.html
https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetWriter.html


-------------------------------------------------------------
################################################
Data type objects (dtype)
################################################

https://docs.scipy.org/doc/numpy-1.10.1/reference/arrays.dtypes.html
https://stackoverflow.com/questions/37561991/what-is-dtypeo-in-pandas
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html
https://arrow.apache.org/docs/python/generated/pyarrow.Schema.html
https://arrow.apache.org/docs/python/api/datatypes.html
https://www.programcreek.com/python/example/126834/pyarrow.uint64
https://stackoverflow.com/questions/66223730/how-to-change-column-datatype-with-pyarrow

'b'       boolean
'i'       (signed) integer
'u'       unsigned integer
'f'       floating-point
'c'       complex-floating point
'O'       (Python) objects
'S', 'a'  (byte-)string
'U'       Unicode
'V'       raw data (void)



-------------------------------------------------------------
https://www.w3schools.com/python/python_lambda.asp
https://www.geeksforgeeks.org/python-lambda-anonymous-functions-filter-map-reduce/
https://stackoverflow.com/questions/57152182/how-can-i-evaluate-an-array-of-lambda-functions
https://stackoverflow.com/questions/290424/filter-a-python-list-by-predicate
https://www.geeksforgeeks.org/python-lambda-function-to-check-if-value-is-in-a-list/
https://www.codegrepper.com/code-examples/python/apply+lambda+on+array+python
https://stackoverflow.com/questions/13669252/what-is-key-lambda
https://www.learnbyexample.org/python-lambda-function/
https://www.learnbyexample.org/python-lambda-function/
https://www.codegrepper.com/code-examples/python/use+lambda+to+map+values
https://cs.stanford.edu/people/nick/py/python-map-lambda.html
https://thispointer.com/python-map-function-explained-with-examples/
https://pythonguides.com/python-dictionary-find-a-key-by-value/

https://docs.aws.amazon.com/lambda/latest/dg/python-handler.html
https://stackoverflow.com/questions/40931783/lambda-function-returning-the-key-value-for-use-in-defaultdict

-------------------------------------------------------------
################################################
from_pandas(type cls, df, Schema schema=None)
################################################

https://www.kaggle.com/code/krsna540/holmes-deductions
https://github.com/apache/arrow/issues/2244
https://arrow.apache.org/docs/python/generated/pyarrow.Table.html
https://enpiar.com/arrow-site/docs/python/generated/pyarrow.Table.html
https://www.kaggle.com/code/krsna540/holmes-deductions
https://intellij-support.jetbrains.com/hc/en-us/community/posts/360002747679-pyarrow-analysis-unexpected-argument-for-pa-Table-from-pandas

cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]
input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)
input_mask = tf.ones_like(input_word_ids).to_tensor()

type_cls = tf.zeros_like(cls)
-------------------------------------------------------------


