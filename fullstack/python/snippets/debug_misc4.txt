####################################################
pyarrow append
####################################################

https://stackoverflow.com/questions/47113813/using-pyarrow-how-do-you-append-to-parquet-file
https://stackoverflow.com/questions/32940416/methods-for-writing-parquet-files-using-python
https://arrow.apache.org/docs/python/parquet.html

import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq

chunksize=10000 # this is the number of lines

pqwriter = None
for i, df in enumerate(pd.read_csv('sample.csv', chunksize=chunksize)):
    table = pa.Table.from_pandas(df)
    # for the first chunk of records
    if i == 0:
        # create a parquet write object giving it an output file
        pqwriter = pq.ParquetWriter('sample.parquet', table.schema)
    pqwriter.write_table(table)

# close the parquet writer
if pqwriter:
    pqwriter.close()


####################################################
unhashable type list
####################################################

https://rollbar.com/blog/handling-unhashable-type-list-exceptions/
https://bobbyhadz.com/blog/python-typeerror-unhashable-type-list
https://www.datasciencelearner.com/typeerror-unhashable-type-list-fix-easily/
https://itsmycode.com/typeerror-unhashable-type-list/
https://stackoverflow.com/questions/62750576/write-nested-parquet-format-from-python

# load packages

import pandas as pd
import json
import pyarrow as pa
import pyarrow.parquet as pq

# Create dummy data
# dummy data with JSON as string
person_data = {'Name':  ['Bob'],
        'Age': [25],
        'languages': "{'mother_language': 'English', 'other_languages': ['German', 'French']}"
        }

# from dict to panda df
person_df = pd.DataFrame.from_dict(person_data)

# from panda df to pyarrow table
person_pat = pa.Table.from_pandas(person_df)

# save as parquet file
pq.write_table(person_pat, 'output/example.parquet')

# load dummy data
sample = pa.parquet.read_table('output/example.parquet')

# transform to dict
sample_dict = sample.to_pydict()
# print with indent for checking
print(json.dumps(sample_dict, sort_keys=True, indent=4))
# load json from string and replace string
sample_dict['languages'] = json.loads(str(sample_dict['languages']))
print(json.dumps(sample_dict, sort_keys=True, indent=4))
#type(sample_dict['languages'])


####################################################
'list' object has no attribute 'values' when we are using append
####################################################

https://datascience.stackexchange.com/questions/62819/list-object-has-no-attribute-values-when-we-are-using-append-in-python
https://researchdatapod.com/how-to-solve-python-attributeerror-list-object-has-no-attribute-apply/
https://bobbyhadz.com/blog/python-attributeerror-list-object-has-no-attribute

y =y.values().astype(int)

convert y to a list of integers you can use list comprehension:
y = [int(x) for x in y]

use map as alternative:
y = list(map(int, y))

lst = ["2", "4", "6", "8", "10", "12"]
lst.apply(lambda x: int(x)
print(lst)

lst = ["2", "4", "6", "8", "10", "12"]
int_lst = [int(x) for x in lst]
print(int_lst)

lst = ["2", "4", "6", "8", "10", "12"]
int_lst = list(map(int, lst))
print(int_lst)


####################################################
AttributeError: 'list' object has no attribute 'reset_index'
####################################################

https://stackoverflow.com/questions/56213580/attributeerror-list-object-has-no-attribute-reset-index

new.groupby('car').price

https://docs.sqlalchemy.org/en/14/core/connections.html#sqlalchemy.engine.Connection.execution_options.params.max_row_buffer
https://docs.sqlalchemy.org/en/14/core/connections.html


####################################################
How do I use itertools.groupby()?
####################################################

https://stackoverflow.com/questions/773/how-do-i-use-itertools-groupby
https://www.geeksforgeeks.org/itertools-groupby-in-python/
https://www.pythonpool.com/pythons-itertools-groupby/


# want to use it like itertools.groupby()
import itertools
# want to use directly
from itertools import groupby

groups = []
uniquekeys = []
for k, g in groupby(data, keyfunc):
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)


from itertools import groupby
things = [("animal", "bear"), ("animal", "duck"), ("plant", "cactus"), ("vehicle", "speed boat"), ("vehicle", "school bus")]
for key, group in groupby(things, lambda x: x[0]):
    for thing in group:
        print("A %s is a %s." % (thing[1], key))
    print("")


for key, group in groupby(things, lambda x: x[0]):
    listOfThings = " and ".join([thing[1] for thing in group])
    print(key + "s:  " + listOfThings + ".")




import itertools
string = 'aaaabbbbbbcccdddddd'
string_tuple = itertools.groupby(string)
print(string_tuple, type(string_tuple))

for item in string_tuple:
    print(item)

for key, iter_item in string_tuple:
    print(f"Key:{key}")
    for item in iter_item:
        print(item,end=" ")
    print()


import itertools

anagrams =['angel','below','glean','bored','robed','study','dusty','cat','act','inch','chin','taste','state','elbow']
grouped_anagrams = [list(group) for key, group in itertools.groupby(sorted(anagrams, key=sorted),sorted)]
print(grouped_anagrams)


https://note.nkmk.me/en/python-itertools-groupby/

import itertools

l = [0, 0, 0, 1, 1, 2, 0, 0]
print([(k, list(g)) for k, g in itertools.groupby(l)])
# [(0, [0, 0, 0]), (1, [1, 1]), (2, [2]), (0, [0, 0])]
print([k for k, g in itertools.groupby(l)])
# [0, 1, 2, 0]

print([list(g) for k, g in itertools.groupby(l)])
# [[0, 0, 0], [1, 1], [2], [0, 0]]

print([(k, list(g)) for k, g in itertools.groupby(l)])
# [(0, [0, 0, 0]), (1, [1, 1]), (2, [2]), (0, [0, 0])]


####################################################
Python - TypeError: 'object' object is not iterable
####################################################

print(dir(perfectNum))
print(list(perfectNum))
print(list(dict(some_map).items())[:3])


####################################################
Python - print map object
####################################################

some_map = map(....)

import csv
dictsome = dict(some_map)
with open('some.csv', 'w') as f:
    f.write("key;value\n")
    for key in dictsome.keys():
        f.write("%s; %s\n" % (key, dictsome[key]))

some_csv = pd.read_csv("some.csv", delimiter=';', sep=';', usecols=['key','value'], skipinitialspace=True)
print(some_csv.head(3))

####################################################
AttributeError:
'dict' object has no attribute '__next__'
'list' object has no attribute '__next__'
####################################################

https://stackoverflow.com/questions/18547878/attribute-error-next

# iterable
pr1 = (x for x in dict(df.to_dict()).values())
print(pr1)
print(pr1.__next__())


####################################################
pyarrow Table
####################################################

https://arrow.apache.org/docs/python/api/datatypes.html
https://arrow.apache.org/docs/cpp/datatypes.html
https://arrow.apache.org/cookbook/py/schema.html#setting-the-data-type-of-an-arrow-array
https://arrow.apache.org/cookbook/py/schema.html
https://arrow.apache.org/docs/python/generated/pyarrow.Table.html
https://arrow.apache.org/docs/python/generated/pyarrow.schema.html
https://arrow.apache.org/docs/python/generated/pyarrow.Table.html
https://arrow.apache.org/docs/python/generated/pyarrow.Table.html
https://arrow.apache.org/docs/python/generated/pyarrow.RecordBatch.html#pyarrow.RecordBatch.from_pydict
https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetWriter.html
https://arrow.apache.org/docs/python/parquet.html
https://arrow.apache.org/docs/7.0/python/generated/pyarrow.Table.html
https://pitrou.net/arrowdevdoc/python/parquet.html
https://pitrou.net/arrowdevdoc/python/parquet.html


https://spark.apache.org/docs/latest/sql-data-sources-parquet.html
https://wesm.github.io/arrow-site-test/python/generated/pyarrow.Table.html
https://docs-snaplogic.atlassian.net/wiki/spaces/SD/pages/1438227/Parquet+Writer

import pyarrow.parquet as pq

pylist2 = [{'n_legs': 2, 'animals': 'Flamingo'}, {'year': 2021, 'animals': 'Centipede'}]
my_schema2 = pa.schema([
    pa.field('year', pa.int64()),
    pa.field('n_legs', pa.int64()),
    pa.field('animals', pa.string())],
    metadata={"year": "Year of entry"})

table = pa.Table.from_pylist(pylist2, schema=my_schema2)
table.schema

writer = pq.ParquetWriter('test_123_2.parquet', schema=my_schema2)
writer.write_table(table)
writer.close()
df2 = pd.read_parquet('test_123_2.parquet')
print(df2.head(3))

https://github.com/apache/arrow/issues/13142
https://stackoverflow.com/questions/56981659/how-to-write-parquet-with-user-defined-schema-through-pyarrow
https://stackoverflow.com/questions/33813815/how-to-read-a-parquet-file-into-pandas-dataframe
https://snyk.io/advisor/python/pyarrow/functions/pyarrow.Table.from_pandas
https://stackoverflow.com/questions/49565713/assign-schema-to-pa-table-from-pandas
https://docs.python.org/3/library/sqlite3.html


-------------------------------------------------------------------




