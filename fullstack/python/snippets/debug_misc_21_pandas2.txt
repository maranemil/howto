
#################################
# check values column nan
#################################

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html
https://stackoverflow.com/questions/20319813/how-to-check-list-containing-nan
https://linuxhint.com/python-remove-nan-from-list/
https://fedingo.com/how-to-remove-nan-from-list-in-python/
https://thispointer.com/check-if-a-numpy-array-contains-any-nan-value/
https://www.youtube.com/watch?v=E2xgnrrmJc8
https://www.adamsmith.haus/python/answers/how-to-check-for-nan-elements-in-a-numpy-array-in-python
https://www.codegrepper.com/code-examples/python/test+if+list+contains+nans
https://splunktool.com/how-to-check-list-containing-nan

import math
from numpy import nan
L1 = [10, nan, 20, nan, 30, nan, 40, nan, 50]
print(L1)
L2 = [item for item in L1 if not(math.isnan(item) = = False]
print(L2)


import numpy as np
from numpy import nan
Arr1 = np.array([nan, 88, nan, 36, nan, 49, nan]
print(Arr1)
Arr2 = Arr1 [ np.logica_not 9np.insan(Arr1))]
print(Arr2)


import pandas as pd
from numpy import nan
L1 = [‘John’, nan, ‘marry’, nan, ‘william’, nan, nan, ‘fredick’ ]
print(L1)
L2 = [item for item in L1 if  not(pd.isnull(item) = = True]
print(L2)


from numpy import nan
L1 = [‘John’, nan, ‘marry’, nan, ‘william’, nan, nan, ‘fredick’ ]
print(L1)
L2 =[ ]
For i in L1
If str(i) != ‘nan’
L2.append(i)
print(L2)


from numpy import nan
L1 = [‘John’, nan, ‘marry’, nan, ‘william’, nan, nan, ‘fredick’ ]
print(L1)
L2 = [item for item in L1 if  str( (item) = = ‘nan’]
print(L2)

#################################
# check none in list
#################################
df = pd.read_csv("file.csv")
for col in df.columns:
    count_df_col = df.groupby(col, dropna=False)[col].count()
    list_values = list(count_df_col.keys().values)
    if count_df_col.count() == 1:
        print('~~~~~~~', col, len(df[col].value_counts(dropna=False)))
        list_nan = [item for item in list_values if str(item) == 'nan']
        print(list_values)
        print(list_nan)

        if str(list_nan[0]) == 'nan':
            print(list_nan[0])

# check index values
print('----')
print(df.index[0])
# print(df.index.names)
# print(df.index.values[0])
df_indx = df.groupby('index_name', dropna=False).count()
print(df_indx.index.values)
print(list(df.groupby('colname', dropna=False).count().value_counts().keys()))


#################################
# pandas counts values
#################################

https://dfrieds.com/data-analysis/value-counts-python-pandas.html


import pandas as pd
import seaborn as sns

df = sns.load_dataset('titanic')
df.head(2)
df['sex'].value_counts()
df['sex'].value_counts(ascending=True)
df['sex'].value_counts(normalize=True)
df['fare'].describe()
df['fare'].value_counts(bins=7)

https://www.width.ai/pandas/count-specific-value-in-column-with-pandas

import pandas as pd
import numpy as np
df = pd.DataFrame(columns=['first','last','score'])
df['first'] = ['jack','jill','bob','matt','john']
df['last'] = ['smith','johnson','smith','payne','hand']
df['score'] = [87,77,99,77,77]
df['score'].value_counts()[77]
# returns 3


import pandas as pd
import numpy as np
df = pd.DataFrame(columns=['first','last','score'])
df['first'] = ['jack','jill','bob','matt','john']
df['last'] = ['smith','johnson','smith','payne','hand']
df['score'] = [87,77,99,77,77]
df[df.last == 'smith'].shape[0]



import pandas as pd
import numpy as np
df = pd.DataFrame(columns=['first','last','score'])
df['first'] = ['jack','jill','bob','matt','john']
df['last'] = ['smith','johnson','smith','payne','hand']
df['score'] = [87,77,99,77,77]
df.head()
len(df[df.score == 77])


https://www.geeksforgeeks.org/how-to-count-occurrences-of-specific-value-in-pandas-column/


# import pandas module
import pandas as pd

# create a dataframe
# with 5 rows and 4 columns
data = pd.DataFrame({
    'name': ['sravan', 'ojsawi', 'bobby',  'rohith',
             'gnanesh', 'sravan', 'sravan', 'ojaswi'],
    'subjects': ['java', 'php', 'java', 'php', 'java',
                 'html/css', 'python', 'R'],
    'marks': [98, 90, 78, 91, 87, 78, 89, 90],
    'age': [11, 23, 23, 21, 21, 21, 23, 21]
})

# count values in name column
print(data['name'].value_counts()['sravan'])

# count values in subjects column
print(data['subjects'].value_counts()['php'])

# count values in marks column
print(data['marks'].value_counts()[89])



https://www.geeksforgeeks.org/count-values-in-pandas-dataframe/
-----------------------------------------------------------------
import numpy as np
import pandas as pd
NaN = np.nan
dataframe = pd.DataFrame({'Name': ['Shobhit', 'Vaibhav',
                                   'Vimal', 'Sourabh',
                                   'Rahul', 'Shobhit'],
                          'Physics': [11, 12, 13, 14, NaN, 11],
                          'Chemistry': [10, 14, NaN, 18, 20, 10],
                          'Math': [13, 10, 15, NaN, NaN, 13]})

display(dataframe)
# using dataframe.count()
# to count all values
dataframe.count()
# we can pass either axis=1 or
# axos='columns' to count with respect to row
print(dataframe.count(axis = 1))

print(dataframe.count(axis = 'columns'))
# it will give the count
# of individual columns count of null values
print(dataframe.isnull().sum())

# it will give the total null
# values present in our dataframe
print("Total Null values count: ",
      dataframe.isnull().sum().sum())

# Count of students whose physics marks
# are greater than 10,chemistry marks are
# greater than 11 and math marks are greater than 9.
print("Count of students ->",
      dataframe[(dataframe['Physics'] > 10) &
                (dataframe['Chemistry'] > 11) &
                (dataframe['Math'] > 9)]['Name'].count())

# dataframe of above result
dataframe[(dataframe['Physics'] > 10 ) &
          (dataframe['Chemistry'] > 11 ) &
          (dataframe['Math'] > 9 )]



https://kanoki.org/2020/03/09/how-to-use-pandas-count-and-value_counts/
-----------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.randint(0, 5, (5, 3)), columns=["A", "B","C"])
df.replace(1,np.nan,inplace=True)
df.shape
df.count(0)
df.count(1)

idx = pd.MultiIndex.from_tuples([('Chris',48), ('Brian',np.nan), ('David',65),('Chris',34),('John',28)],
                                 names=['Name', 'Age'])
col = ['Salary']
df = pd.DataFrame([120000, 140000, 90000, 101000, 59000], idx, col)
df
df.count(level='Name')
df=df.reset_index()
df.groupby(by='Name').count()
df['freq']=df.groupby(by='Name')['Name'].transform('count')
df


https://www.statology.org/pandas-count-values-in-column-with-condition/
-----------------------------------------------------------------

import pandas as pd

#create DataFrame
df = pd.DataFrame({'team': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],
                   'pos': ['Gu', 'Fo', 'Fo', 'Fo', 'Gu', 'Gu', 'Fo', 'Fo'],
                   'points': [18, 22, 19, 14, 14, 11, 20, 28]})

#view DataFrame
print(df)
#count number of values in team column where value is equal to 'A'
len(df[df['team']=='A'])
#count rows where team is 'B' and pos is 'Gu'
len(df[(df['team']=='B') & (df['pos']=='Gu')])
#count rows where team is 'B' and pos is 'Gu' and points > 15
len(df[(df['team']=='B') & (df['pos']=='Gu') & (df['points']>12)])


https://www.marsja.se/pandas-count-occurrences-in-column-unique-values/
-----------------------------------------------------------------

import pandas as pd

# URL to .csv file
data_url = 'https://vincentarelbundock.github.io/Rdatasets/csv/carData/Arrests.csv'
# Reading the data
df = pd.read_csv(data_url, index_col=0)
# pandas count distinct values in column
df['sex'].value_counts()
# pandas count unique values ascending:
df['sex'].value_counts(ascending=True)

import numpy as np
# Copying the dataframe
df_na = df
# Adding 10 missing values to the dataset
df_na.iloc[[1, 6, 7, 8, 33,
            44, 99, 103, 109, 201], 4] = np.NaN
# Counting occurences as well as missing values:
df_na['sex'].value_counts(dropna=False)
df['sex'].value_counts(normalize=True)
df['age'].describe()
# pandas count unique values in bins:
df['age'].value_counts(bins=5)


# create a dict of lists
data = {'Language':['Python', 'Python',
                   'Javascript',
                   'C#', 'PHP'],
       'University':['LiU', 'LiU',
              'UmU', 'GU','UmU'],
       'Age':[22, 22, 23, 24, 23]}

# Creating a dataframe from the dict
df3 = pd.DataFrame(data)
df3.head()
df3.apply(pd.value_counts)
# Count occurences of certain value (i.e. Male) in a column (i.e., sex)
df.sex.value_counts().Male
# count unique values with pandas size:
df.groupby('sex').size()
# counting unique values with pandas groupby and count:
df.groupby('sex').count()


##########################################################
grouped
##########################################################

https://www.saltycrane.com/blog/2014/10/example-using-groupby-and-defaultdict-do-same-task/
https://stackoverflow.com/questions/3749512/python-group-by
https://www.guru99.com/python-howto-remove-duplicates.html
https://stackoverflow.com/questions/4459703/how-to-make-lists-contain-only-distinct-element-in-python
https://stackoverflow.com/questions/36106490/how-to-get-unique-values-from-multiple-columns-in-a-pandas-groupby
https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html
https://stackoverflow.com/questions/35058435/how-to-read-index-data-as-string-with-pandas-read-csv
https://pandas.pydata.org/docs/reference/api/pandas.Index.values.html


SOME_DATA = [
    {'model': u'Yaris', 'some_value': 11202, 'trim_name': u'3-Door L Manual'},
    {'model': u'Yaris', 'some_value': 19269, 'trim_name': u'3-Door LE Automatic'},
    {'model': u'Corolla', 'some_value': 27119, 'trim_name': u'L Automatic'},
    {'model': u'Corolla', 'some_value': 32262, 'trim_name': u'LE'}
]

import collections

grouped = collections.defaultdict(list)
for item in SOME_DATA:
    grouped[item['model']].append(item)

for model, group in grouped.items():
    print
    print model
    pprint(group, width=150)


...

import itertools

def keyfunc(x):
    return x['model']

SOME_DATA = sorted(SOME_DATA, key=keyfunc)
for model, group in itertools.groupby(SOME_DATA, keyfunc):
    print
    print model
    pprint(list(group), width=150)


...

https://www.geeksforgeeks.org/group-list-of-dictionary-data-by-particular-key-in-python/


# import a groupby() method
# from itertools module
from itertools import groupby

# dictionary
INFO = [
    {'employee': 'XYZ_1', 'company': 'ABC_1'},
    {'employee': 'XYZ_2', 'company': 'ABC_2'},
    {'employee': 'XYZ_3', 'company': 'ABC_3'},
    {'employee': 'XYZ_4', 'company': 'ABC_3'}
]

# define a function for key
def key_func(k):
    return k['company']

# sort INFO data by 'company' key.
INFO = sorted(INFO, key=key_func)

for key, value in groupby(INFO, key_func):
    print(key)
    print(list(value))

...

# import required methods
from itertools import groupby
from operator import itemgetter

# dictionary
students = [
    {'mark': '65', 'grade': 'C'},
    {'mark': '86', 'grade': 'A'},
    {'mark': '73', 'grade': 'B'},
    {'mark': '49', 'grade': 'D'},
    {'mark': '91', 'grade': 'A'},
    {'mark': '79', 'grade': 'B'}
]

# Sort students data by grade key.
students = sorted(students,
                  key = itemgetter('grade'))

# Display data grouped by grade
for key, value in groupby(students,
                          key = itemgetter('grade')):
    print(key)
    for k in value:
        print(k)

################################################
How to Rename Columns in Pandas
################################################

https://www.statology.org/pandas-rename-columns/
https://www.geeksforgeeks.org/how-to-rename-columns-in-pandas-dataframe/
https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html


Method 1: Rename Specific Columns
df.rename(columns = {'old_col1':'new_col1', 'old_col2':'new_col2'}, inplace = True)


Method 2: Rename All Columns
df.columns = ['new_col1', 'new_col2', 'new_col3', 'new_col4']


Method 3: Replace Specific Characters in Columns
df.columns = df.columns.str.replace('old_char', 'new_char')

##########################
pandas drop NA NAN
##########################

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html
https://www.geeksforgeeks.org/python-pandas-dataframe-replace/
https://datatofish.com/replace-values-pandas-dataframe/
https://www.w3schools.com/python/pandas/ref_df_replace.asp
https://stackoverflow.com/questions/27060098/replacing-few-values-in-a-pandas-dataframe-column-with-another-value
https://stackoverflow.com/questions/13295735/how-to-replace-nan-values-by-zeroes-in-a-column-of-a-pandas-dataframe


index_keys = df.index.names
index_values = list(df.index[0])
row_data = {index_keys[i]: index_values[i] for i in range(len(index_keys))}
row_data_df  = pd.DataFrame(pd.Series(row_data)).dropna() # removes column
row_data_df = row_data_df.fillna(0) # fill 0
row_data_df = row_data_df.fillna('')
print("\nrow_data ", row_data)
print("\nrow_data ", row_data_df)


##########################################################################
Python | Pandas DataFrame.set_index()
Set MultiIndex of an existing DataFrame in pandas
##########################################################################

https://pythonexamples.org/pandas-set-column-as-index/
https://www.geeksforgeeks.org/python-pandas-dataframe-set_index/
https://www.w3schools.com/python/pandas/ref_df_index.asp
https://pandas.pydata.org/docs/reference/api/pandas.Index.html
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html
https://pandas.pydata.org/docs/reference/api/pandas.Index.html
https://pandas.pydata.org/docs/user_guide/indexing.html
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html
https://stackoverflow.com/questions/24041436/set-multiindex-of-an-existing-dataframe-in-pandas

DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)

df = df.set_index(['Company', 'date'], inplace=True)
df.set_index(['Company', 'date'], inplace=True)


is_none = df.set_index(['Company', 'date'], inplace=True)
df  # the dataframe you want
is_none # has the value None

...

# importing pandas package
import pandas as pd
# making data frame from csv file
data = pd.read_csv("employees.csv")
# setting first name as index column
data.set_index(["First Name", "Gender"], inplace = True,
                            append = True, drop = False)
# display
data.head()

...

import pandas as pd
#initialize a dataframe
df = pd.DataFrame(
	[[21, 'Amol', 72, 67],
	[23, 'Lini', 78, 69],
	[32, 'Kiku', 74, 56],
	[52, 'Ajit', 54, 76]],
	columns=['rollno', 'name', 'physics', 'botony'])

print('DataFrame with default index\n', df)

#set column as index
df = df.set_index('rollno')

print('\nDataFrame with column as index\n',df)



...

df = pd.DataFrame({'month': [1, 4, 7, 10],
                   'year': [2012, 2014, 2013, 2014],
                   'sale': [55, 40, 84, 31]})
df.set_index(['year', 'month'])



##########################################################################
show all columns / rows of a Pandas Dataframe
##########################################################################
https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf
https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html

pd.reset_option(“max_columns”)
movies.head()
movies.head(20)

pd.set_option(“max_colwidth”, None)
movies[[“Title”, “Plot”]].head()

pd.set_option("max_columns", 2) #Showing only two columns
pd.set_option("max_rows", None)


print("Default max_rows: {} and min_rows: {}".format(
pd.get_option("max_rows"), pd.get_option("min_rows")))
pd.set_option(“min_rows”, 2)

pd.set_option(“max_seq_item”, None)
movies.head()
pd.set_option(‘precision’, 2)
movies[[‘imdbRating’]].head()

...

import pandas as pd
titanic = pd.read_csv("data/titanic.csv")
titanic.head()
ages = titanic["Age"]
ages.head()
print(titanic.iloc[5][:20])

type(titanic["Age"])
pandas.core.series.Series
titanic["Age"].shape


age_sex = titanic[["Age", "Sex"]]
age_sex.head()

type(titanic[["Age", "Sex"]])
pandas.core.frame.DataFrame
titanic[["Age", "Sex"]].shape

above_35 = titanic[titanic["Age"] > 35]
above_35.head()
above_35.shape
titanic["Age"] > 35

class_23 = titanic[titanic["Pclass"].isin([2, 3])]
class_23.head()
class_23 = titanic[(titanic["Pclass"] == 2) | (titanic["Pclass"] == 3)]
class_23.head()

age_no_na = titanic[titanic["Age"].notna()]
age_no_na.head()
age_no_na.shape

adult_names = titanic.loc[titanic["Age"] > 35, "Name"]
adult_names.head()
titanic.iloc[9:25, 2:5]
titanic.iloc[0:3, 3] = "anonymous"
titanic.head()


https://www.geeksforgeeks.org/how-to-retrieve-an-entire-row-or-column-of-an-array-in-python/
https://thispointer.com/python-numpy-select-rows-columns-by-index-from-a-2d-ndarray-multi-dimension/
https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html


import numpy as np

# creating a numpy character array
arr1 = np.array(["Ram", "Shyam" , "Sita"])

print("First row - ")
print(arr1)

# printing first column referred by first index
print ("First Column")
print (arr1[0])

# computing length of array
length = len(arr1)
print("Last Column")
print (arr1[length-1])




###############################################################################################
ValueError: Boolean array expected for the condition, not object in unittest
###############################################################################################

https://jtuto.com/valueerror-boolean-array-expected-for-the-condition-not-object-in-unittest/
https://pandas.pydata.org/docs/reference/api/pandas.notnull.html
https://www.appsloveworld.com/pandas/100/323/pandas-mask-with-boolean-operation-valueerror-boolean-array-expected-for-the-co
https://stackoverflow.com/questions/65836268/valueerror-boolean-array-expected-for-the-condition-not-object


###############################################################################################
valueError: Can't infer object conversion type: 0    1990-01-01
ValueError: Can't infer object conversion type: 0
###############################################################################################

https://stackoverflow.com/questions/46546946/date-can-not-be-serialized
https://github.com/dask/fastparquet/issues/458
https://github.com/dask/fastparquet/issues/469
https://programtalk.com/python-more-examples/pandas.period_range/?ipage=7


import pandas as pd
dob = pd.Series(['1954-01-01', '1981-11-15', '1993-01-21', '1948-01-01',
                 '1977-01-01', '1968-04-28', '1969-01-01', '1989-01-01',
                 '1985-01-01'], name='dob')


pd.to_datetime(dob)
baz = list(range(9))
foo = pd.DataFrame(baz, index=pd.to_datetime(dob), columns=['dob'])
from fastparquet import write
write('foo.parquet', foo)


------------

from decimal import Decimal
import pandas as pd
d = [{'CAD': Decimal('1.3126054674'), 'HKD': Decimal('7.7500843739'), 'ISK': Decimal('138.8795140061'), 'PHP': Decimal('48.5479244009'), 'DKK': Decimal('6.2801214985'), 'HUF': Decimal('307.12959838'), 'CZK': Decimal('22.9370570368')}]
df = pd.DataFrame(d)
filepath = "test.parquet"
parquet_engine = "fastparquet"
compression="snappy"
df.to_parquet(filepath, engine=parquet_engine, compression=compression)

------------

import pandas as pd
df = pd.DataFrame({"receipt_date": [pd.datetime(2021, 10, 11), ] * 1000})
df.receipt_date = df.receipt_date.dt.date
df.to_parquet('dummy')

#################################################################
AttributeError: type object 'object' has no attribute 'dtype'
#################################################################

https://www.roseindia.net/answers/viewqa/pythonquestions/265593-AttributeError-type-object-object-has-no-attribute-dtype-.html

This error comes when you are creating empty pandas dataframe. To resolve this you have to upgrade pandas version.

Upgrade pandas to:
pandas==0.25.3 into pandas==1.2.3
or latest version

Command to upgrade pandas:
pip install pandas==1.4.1

https://dille.name/media/2019/01/Is%20Docker%20making%20us%20more%20secure%20or%20less.pdf




##################################################
Pandas Filter by Column Value
Quick Examples of pandas Filter by Column Value
##################################################

https://sparkbyexamples.com/pandas/pandas-filter-by-column-value/
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html

# Filter Rows using DataFrame.query()
df2=df.query("Courses == 'Spark'")

#Using variable
value='Spark'
df2=df.query("Courses == @value")

#inpace
df.query("Courses == 'Spark'",inplace=True)

#Not equals, in & multiple conditions
df.query("Courses != 'Spark'")
df.query("Courses in ('Spark','PySpark')")
df.query("`Courses Fee` >= 23000")
df.query("`Courses Fee` >= 23000 and `Courses Fee` <= 24000")

# Other ways to Filter Rows
df.loc[df['Courses'] == value]
df.loc[df['Courses'] != 'Spark']
df.loc[df['Courses'].isin(values)]
df.loc[~df['Courses'].isin(values)]
df.loc[(df['Discount'] >= 1000) & (df['Discount'] <= 2000)]
df.loc[(df['Discount'] >= 1200) & (df['Fee'] >= 23000 )]

df[df["Courses"] == 'Spark']
df[df['Courses'].str.contains("Spark")]
df[df['Courses'].str.lower().str.contains("spark")]
df[df['Courses'].str.startswith("P")]

# Filter by multiple conditions
print(df.query("`Courses Fee` >= 23000 and `Courses Fee` <= 24000"))

# By using lambda function
print(df.apply(lambda row: row[df['Courses'].isin(['Spark','PySpark'])]))

# filter rows by ignoreing columns that have None & Nan values
print(df.dropna())

df.apply(lambda row: row[df['Courses'].isin(['Spark','PySpark'])])
df.dropna()




import pandas as pd
import numpy as np
technologies= {
    'Courses':["Spark","PySpark","Hadoop","Python","Pandas"],
    'Fee' :[22000,25000,23000,24000,26000],
    'Duration':['30days','50days','30days', None,np.nan],
    'Discount':[1000,2300,1000,1200,2500]
          }
df = pd.DataFrame(technologies)
print(df)



##################################################
Count Rows – DataFrame.shape
##################################################
https://pythonexamples.org/pandas-dataframe-count-rows/

import pandas as pd
#initialize dataframe
df = pd.DataFrame({'a': [1, 4, 7, 2], 'b': [2, 0, 8, 7]})
#number of rows in dataframe
num_rows = df.shape[0]
print('Number of Rows in DataFrame :',num_rows)


import pandas as pd
#initialize dataframe
df = pd.DataFrame({'a': [1, 4, 7, 2], 'b': [2, 0, 8, 7]})
#number of rows in dataframe
num_rows = df.count()[0]
print('Number of Rows in DataFrame :',num_rows)

##################################################
Pandas DataFrame count() Method
##################################################

https://www.w3schools.com/python/pandas/ref_df_count.asp
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html

import pandas as pd
data = {
  "Duration": [50, 40, None, None, 90, 20],
  "Pulse": [109, 140, 110, 125, 138, 170]
}
df = pd.DataFrame(data)
print(df.count())
