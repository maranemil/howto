

############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
#	(1) https://github.com/andersbll/neural_artistic_style
#	package requirements
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

#---------------------------------------
# install Conda
#---------------------------------------

https://www.anaconda.com/download/#linux
https://docs.anaconda.com/anaconda/install/linux
https://docs.anaconda.com/anaconda/faq#how-do-i-get-the-latest-anaconda-with-python-3-5
https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/

sh Anaconda2-5.1.0-Linux-x86_64.sh

#---------------------------------------
# Check Conda and Py Libs
#---------------------------------------
conda update conda
conda update anaconda


conda -V
python -V

# scipy
import scipy
print('scipy: %s' % scipy.__version__)
# numpy
import numpy
print('numpy: %s' % numpy.__version__)
# matplotlib
import matplotlib
print('matplotlib: %s' % matplotlib.__version__)
# pandas
import pandas
print('pandas: %s' % pandas.__version__)
# statsmodels
import statsmodels
print('statsmodels: %s' % statsmodels.__version__)
# scikit-learn
import sklearn
print('sklearn: %s' % sklearn.__version__)


conda update scikit-learn
# conda install -c anaconda scikit-learn=0.18.1
conda install theano
conda install -c conda-forge tensorflow

pip install keras

#---------------------------------------
# install deeppy
# https://andersbll.github.io/deeppy-website/installation-guide.html
# https://programtalk.com/vs2/?source=python/635/deeppy/doc/sphinx_ext/gen_rst.py
# http://www.redhub.io/Tensorflow/neural-style/raw/master/vgg.py
# https://github.com/andersbll/cudarray
#---------------------------------------
git clone https://github.com/andersbll/deeppy
cd deeppy
#sudo python setup.py install
sudo python setup.py --without-cuda install


############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
# 	(2) https://github.com/anishathalye/neural-style
# 	package requirements
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

#---------------------------------------
# https://github.com/andersbll/neural_artistic_style/wiki/Installation-guide
# error: Network imagenet-vgg-verydeep-19.mat does not exist. (Did you forget to download it?)
# https://arxiv.org/pdf/1409.1556.pdf
#---------------------------------------

pip install tensorflow

http://www.vlfeat.org/matconvnet/pretrained/

# ValueError: You're using the wrong VGG19 data. Please follow the instructions in the README to download the correct data.
http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-16.mat # wrong
http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat # wrong

# TypeError: Expecting miMATRIX type here, got 3076465338
http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat

Usage:
python neural_style.py --content examples/1-content.jpg  --styles examples/1-style.jpg  --output output.jpg







############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
#	(3) https://github.com/dsgiitr/Neural-Style-Transfer
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

// req keras.applications.vgg16
https://drive.google.com/a/d-o-m.org/uc?id=0Bz7KyqmuGsilT0J5dmRCM0ROVHc&export=download
https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view
vgg16_weights.h5

https://gist.github.com/Thimira/c369aea98c4268042425649a6a687d8f#file-vgg16_predict-py
https://keras.io/applications/#vgg16
https://github.com/keras-team/keras/blob/master/keras/applications/vgg16.py
https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16
https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98
https://github.com/MarcBS/keras

sudo pip install keras

sudo pip uninstall keras
sudo pip install git+https://github.com/fchollet/keras.git



jupyter notebook  Keras_styletransfer.ipynb
ImportError: No module named keras.applications.vgg16


############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
#	(4) https://github.com/fzliu/style-transfer
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

## Requirements

 - Python >= 2.7
 - CUDA >= 6.5 (highly recommended)
 - Caffe

numpy>=1.7.1
scipy>=0.13.2
scikit-image>=0.9.3
progressbar>=2.3

python style.py -s <style_image> -c <content_image> -m <model_name> -g 0
python style.py -s images/style/starry_night.jpg -c images/content/nanjing.jpg -m models/vg16 -g 0

----------------
# 1. Caffe + Anaconda
https://gist.github.com/arundasan91/b432cb011d1c45b65222d0fac5f9232c
https://gist.github.com/titipata/f0ef48ad2f0ebc07bcb9
----------------
	bash Anaconda2-2.5.0-Linux-x86_64.sh
	conda -V
	sudo apt-get install libopenblas-dev -y
	sudo apt-get install libboost-all-dev -y
	conda install opencv
	sudo apt-get install libopencv-dev -y

	# install some dependencies of Caffe. Run the following:

	sudo apt-get install libleveldb-dev libsnappy-dev libhdf5-serial-dev -y
	sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev -y
	sudo apt-get install protobuf-compiler libprotobuf-dev -y
	conda install -c https://conda.anaconda.org/anaconda protobuf

sudo apt-get install git

	#clone the official Caffe repository from Github.
	git clone https://github.com/BVLC/caffe

	#Once the git is cloned, cd into caffe folder.
	cd caffe
	cp Makefile.config.example Makefile.config
	# Adjust Makefile.config (for example, if using Anaconda Python)
	make all
	make test
	make runtest

open the Makefile.config and add

	1. Uncomment (No space in the beginning):
	CPU_ONLY := 1

	2. Change:
	BLAS := atlas to BLAS := open

	3. Comment out:
	PYTHON_INCLUDE := /usr/include/python2.7 \
	        /usr/lib/python2.7/dist-packages/numpy/core/include

	4. Uncomment:
	ANACONDA_HOME := $(HOME)/anaconda2

	PYTHON_INCLUDE := $(ANACONDA_HOME)/include \
	    $(ANACONDA_HOME)/include/python2.7 \
	    $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include

	5. Comment:
	PYTHON_LIB := /usr/lib

	6. Uncomment:
	PYTHON_LIB := $(ANACONDA_HOME)/lib

	7. Uncomment:
	USE_PKG_CONFIG := 1
l

cd ~/caffe/python
sudo apt-get install python-pip && sudo pip install -r requirements.txt


----------------
# Caffe Installation
https://gist.github.com/titipata/f0ef48ad2f0ebc07bcb9
http://caffe.berkeleyvision.org/installation.html
https://keras.io/applications/
https://keras.io/applications/#vgg16
---------------


	lspci | grep -i nvidia
	uname -m && cat /etc/*release
	 gcc --version

	wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_6.5-14_amd64.deb
	sudo dpkg -i cuda-repo-ubuntu1404_6.5-14_amd64.deb
	sudo apt-get update
	sudo apt-get install cuda

	sudo apt-get install libopenblas-dev git unzip

	wget https://raw.githubusercontent.com/jayrambhia/Install-OpenCV/master/Ubuntu/2.4/opencv2_4_9.sh
	chmod +x opencv2_4_9.sh
	./opencv2_4_9.sh

	wget http://09c8d0b2229f813c1b93-c95ac804525aac4b6dba79b00b39d1d3.r79.cf1.rackcdn.com/Anaconda-2.1.0-Linux-x86_64.sh
	bash Anaconda-2.1.0-Linux-x86.sh

	sudo apt-get install libboost-all-dev

	sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev
	sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler

	pip install protobuf

	git clone https://github.com/BVLC/caffe
	cp Makefile.config.example Makefile.config
	# Adjust Makefile.config (for example, if using Anaconda Python)
	make all
	make test
	make runtest

	rm ~/anaconda/lib/libm.*
	sudo cp libhdf5_hl.so.7 libhdf5_hl.so.8
	sudo cp libhdf5.so.7 libhdf5.so.8


    added to .bashrc

		# CUDA
		export PATH=/usr/local/cuda-6.5/bin:$PATH
		export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64:$LD_LIBRARY_PATH
		export PATH
		# Anaconda
		export PATH=/home/ubuntu/anaconda/bin:$PATH
		# Caffe Root
		export CAFFE_ROOT=/home/ubuntu/caffe


############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
#	(5) https://github.com/hnarayanan/stylist [OK]
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

https://medium.com/@pushkarmandot/installing-tensorflow-theano-and-keras-in-spyder-84de7eb0f0df
https://chunml.github.io/ChunML.github.io/project/Tensorflow-Installation/
https://anaconda.org/anaconda/keras-gpu
https://gist.github.com/eliasah/04535949e844a189c1d5d2ab718fac0c
http://inmachineswetrust.com/posts/deep-learning-setup/

jupyter notebook neural_style_transfer.ipynb

ImportError: No module named keras

 conda install -c conda-forge keras tensorflow
 pip install keras tensorflow
 conda create -n mytensorflow -c conda-forge tensorflow keras python=2.7
 conda create -n mytensorflowpy35 -c conda-forge python=3.5 tensorflow

#and other stuff activate mytensorflowpy35
conda create -n py35 python=3.5 anaconda
activate py35

model = VGG16(input_tensor=input_tensor, weights='imagenet',
              include_top=False)

Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
14172160/58889256 [======>.......................] - ETA: 41s


---------
### installing_keras_tf.md ###
https://gist.github.com/eliasah/04535949e844a189c1d5d2ab718fac0c
---------

	# create conda env
	conda create --name keras
	source activate keras

	# installing utilities
	conda install python=3.5 numpy scikit-learn=0.18.1 jupyter matplotlib pip
	conda install pandas h5py pillow lxml

	#verifying python version
	python --version

	#installing tensorflow 1.2.1 for python 3.5 cpu only

	pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.1-cp35-cp35m-linux_x86_64.whl
	python -c "import tensorflow as tf"

	# installing keras-2.0.5
	pip install keras # --upgrade

	#verifying keras installation
	python -c "import keras; print(keras.__version__)"


Anaconda Keras / TensorFlow environment setup
https://gist.github.com/jeffgreenca/28e0fe58644b8af48f97a3e18fe08302


	Install TensorFlow (CPU), Keras, and some other tools to a new anaconda environment.
	Open Anaconda Prompt

	conda create --name tensorflow35 python=3.5
	conda activate tensorflow35
	conda install jupyter
	conda install scipy
	conda install spyder

	pip install tensorflow
	pip install pyyaml h5py
	pip install keras
	pip install opencv-python
	pip install matplotlib seaborn argparse


############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
#	(6) https://github.com/junyanz/CycleGAN ((lua))
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

## Prerequisites

- Linux or OSX
- NVIDIA GPU + CUDA CuDNN (CPU mode and CUDA without CuDNN may work with minimal modification, but untested)
- For MAC users, you need the Linux/GNU commands `gfind` and `gwc`, which can be installed with `brew install findutils coreutils`.


## Getting Started

	### Installation
	- Install torch and dependencies from https://github.com/torch/distro
	- Install torch packages `nngraph`, `class`, `display`
	luarocks install nngraph
	luarocks install class
	luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec

	- Clone this repo:
	git clone https://github.com/junyanz/CycleGAN
	cd CycleGAN

	Apply a Pre-trained Model
	bash ./datasets/download_dataset.sh ae_photos
	bash ./pretrained_models/download_model.sh style_cezanne

	# Generate Paul CÃ©zanne style images:
	DATA_ROOT=./datasets/ae_photos name=style_cezanne_pretrained model=one_direction_test phase=test loadSize=256 fineSize=256 resize_or_crop="scale_width" th test.lua

	# Train
	bash ./datasets/download_dataset.sh horse2zebra

	DATA_ROOT=./datasets/horse2zebra name=horse2zebra_model th train.lua
	# CPU only
	DATA_ROOT=./datasets/horse2zebra name=horse2zebra_model gpu=0 cudnn=0 th train.lua	th -ldisplay.start 8000 0.0.0.0

	Finally, test the model:
	DATA_ROOT=./datasets/horse2zebra name=horse2zebra_model phase=test th test.lua

	Model Zoo

	Download the pre-trained models with the following script.
	The model will be saved to ./checkpoints/model_name/latest_net_G.t7.
	bash ./pretrained_models/download_model.sh model_name

	model_name:
		orange2apple
		apple2orange
		horse2zebra
		zebra2horse
		style_monet
		style_vangogh
		style_ukiyoe
		style_cezanne
		monet2photo
		cityscapes_photo2label
		cityscapes_label2photo
		map2sat
		sat2map
		iphone2dslr_flower

		CPU models can be downloaded using:
		bash pretrained_models/download_model.sh <name>_cpu
		where <name> can be horse2zebra, style_monet, etc. You just need to append _cpu to the target model.


	Datasets
	bash ./datasets/download_dataset.sh dataset_name

	facades # 400 images
	cityscapes # 2975 images
	maps # 1096 training images
	horse2zebra # 939 horse images and 1177 zebra images
	apple2orange #  996 apple images and 1020 orange images
	summer2winter_yosemite #  1273 summer Yosemite images and 854 winter Yosemite images
	monet2photo, vangogh2photo, ukiyoe2photo, cezanne2photo
	# Monet:1074, Cezanne:584, Van Gogh:401, Ukiyo-e:1433, Photographs:6853.
	iphone2dslr_flower # iPhone:1813, DSLR:3316.

Display UI
Optionally, for displaying images during training and test, use the display package.

    Install it with: luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec
    Then start the server with: th -ldisplay.start
    Open this URL in your browser: http://localhost:8000

	By default, the server listens on localhost. Pass 0.0.0.0 to allow external connections on any interface:
	th -ldisplay.start 8000 0.0.0.0
	Then open http://(hostname):(port)/ in your browser to load the remote desktop.






############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(7) https://github.com/luanfujun/deep-photo-styletransfer (lua)
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

// ?



############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(8) https://github.com/minimaxir/neural-doodle
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

// ?


############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(9) https://github.com/MJ10/Style  ( Android)
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

## Usage
- Clone the repository
- You can now open the project in Android Studio and build and run the application.

## Libraries
- [TensorFlow](https://tensorflow.org)
- [Anko](https://github.com/Kotlin/anko)
- [CameraKit](https://github.com/gogopop/CameraKit-Android)


############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(10) https://github.com/msokoloff1/Real-Time-Style-Transfer
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

	## Data Requirements

	The following files must be downloaded on your machine and put in the savedNets folder:

	##### 	Microsoft Coco dataset required for training
	http://msvocds.blob.core.windows.net/coco2014/train2014.zip (13GB) !!!!!!!!!!!!!!!!!!!

	##### 	VGG network weights
	https://mega.nz/#!xZ8glS6J!MAnE91ND_WyfZ_8mvkuSa2YcA7q-1ehfSm-Q1fxOvvs
	must be called vgg19.npy


	## Software Requirements
	```
	-Python 3.5
	-Tensorflow 0.12
	-Numpy
	-PILLOW
	-Scipy
	```

	#How To Use
	Make sure that vgg network and the coco dataset are in the savedNets folder.
	####To Train
	```python3 Runner.py -train True```
	####To Perform style transfer
	```python3 Runner.py```
	#####To Find out about all flags
	```python3 Runner.py -h```




############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(11) https://github.com/mtyka/neural-style (lua)
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

// ?

############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(12) https://github.com/mtyka/neural_artistic_style (py)
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

### Requirements
 - [DeepPy](http://github.com/andersbll/deeppy), Deep learning in Python.
 - [CUDArray](http://github.com/andersbll/cudarray) with [cuDNN](https://developer.nvidia.com/cudnn), CUDA-accelerated NumPy.
 - [Pretrained VGG 19 model](http://www.vlfeat.org/matconvnet/pretrained), choose *imagenet-vgg-verydeep-19*.


### Examples
Execute

    python neural_artistic_style.py --subject images/tuebingen.jpg --style images/starry_night.jpg

List command line options with
    python neural_artistic_style.py --help

ImportError: No module named deeppy !!!!!!



############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(13) https://github.com/ShafeenTejani/style-transfer
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

 Requirements

* [Python 2.7](https://www.python.org/download/releases/2.7/)
* [TensorFlow](https://www.tensorflow.org/versions/master/get_started/os_setup#download-and-setup)
* [SciPy & NumPy](http://scipy.org/install.html)
* Download the [pre-trained VGG network](http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat) and place it in the top level of the repository (~500MB)

## Running the code

```python run.py --content <content image> --style <style image> --output <output image path>```

The algorithm will run with the following settings:

```python
ITERATIONS = 1000    # override with --iterations argument
LEARNING_RATE = 1e1  # override with --learning-rate argument
CONTENT_WEIGHT = 5e1 # override with --content-weight argument
STYLE_WEIGHT = 1e2   # override with --style-weight argument
TV_WEIGHT = 1e2      # override with --tv-weight argument
```

To run the style transfer with a GPU run with the `--use-gpu` flag.

python run.py --content examples/dog.jpg  --style examples/starry-night-van-gogh.jpg  --output xyz.jpg
run.py: error: Network imagenet-vgg-verydeep-19.mat does not exist.

?

############################################################################################################
#-----------------------------------------------------#-----------------------------------------------------
(14) https://github.com/slavivanov/Style-Tranfer [OK]
#-----------------------------------------------------#-----------------------------------------------------
############################################################################################################

jupyter notebook style.ipynb

/home/user/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36:
 FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated.
 In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.





























##########################################################################################
#
#  print keras applications
#	https://github.com/keras-team/keras/issues/7946
#
##########################################################################################

from scipy.misc import imsave
import numpy as np
import time
from keras.applications import vgg16
from keras import backend as K

# -----
print(keras.__version__)
import tensorflow as tf
tf.__version__

import pkgutil
import scipy
package=keras.applications
for importer, modname, ispkg in pkgutil.walk_packages(path=package.__path__,
                                                      prefix=package.__name__+'.',
                                                      onerror=lambda x: None):
    print(modname)

keras.applications.imagenet_utils
keras.applications.inception_v3
keras.applications.mobilenet
keras.applications.resnet50
keras.applications.vgg16
keras.applications.vgg19
keras.applications.xception

# floyd run --gpu --env theano --data SyccinddLDdS7p3vzcwGQ2 'python demo.py'




##########################################################################################
#
#	How to install with pip directly from GitHub? (self.Python)
#	https://www.reddit.com/r/Python/comments/2crput/how_to_install_with_pip_directly_from_github/
#
##########################################################################################

Option 1

$ pip install https://github.com/django-extensions/django-extensions/zipball/master
$ pip freeze --local
django-extensions==1.3.9

Option 2

$ pip install git+https://github.com/django-extensions/django-extensions
$ pip freeze --local
django-extensions==1.4.0

Option 2b

$ pip install git+https://github.com/django-extensions/django-extensions.git
$ pip freeze --local
django-extensions==1.4.0

Notice the .git suffix at the end of the pip install... line. It was missing in the previous case.

Option 3

$ pip install -e git+https://github.com/django-extensions/django-extensions.git#egg=django-extensions
$ pip freeze --local
-e git+https://github.com/django-extensions/django-extensions.git@4034b96b1879a14af3c26872e739abcad3fc4f3d#egg=d




##########################################################################################
#
#	Classifying images with VGGNet, ResNet, Inception, and Xception with Python and Keras
#	https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/
#
##########################################################################################

# import the necessary packages
from keras.applications import ResNet50
from keras.applications import InceptionV3
from keras.applications import Xception # TensorFlow ONLY
from keras.applications import VGG16
from keras.applications import VGG19
from keras.applications import imagenet_utils
from keras.applications.inception_v3 import preprocess_input
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
import numpy as np
import argparse
import cv2


# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", required=True,
	help="path to the input image")
ap.add_argument("-model", "--model", type=str, default="vgg16",
	help="name of pre-trained network to use")
args = vars(ap.parse_args())

# define a dictionary that maps model names to their classes
# inside Keras
MODELS = {
	"vgg16": VGG16,
	"vgg19": VGG19,
	"inception": InceptionV3,
	"xception": Xception, # TensorFlow ONLY
	"resnet": ResNet50
}

# esnure a valid model name was supplied via command line argument
if args["model"] not in MODELS.keys():
	raise AssertionError("The --model command line argument should "
		"be a key in the `MODELS` dictionary")


# initialize the input image shape (224x224 pixels) along with
# the pre-processing function (this might need to be changed
# based on which model we use to classify our image)
inputShape = (224, 224)
preprocess = imagenet_utils.preprocess_input

# if we are using the InceptionV3 or Xception networks, then we
# need to set the input shape to (299x299) [rather than (224x224)]
# and use a different image processing function
if args["model"] in ("inception", "xception"):
	inputShape = (299, 299)
	preprocess = preprocess_input

# load our the network weights from disk (NOTE: if this is the
# first time you are running this script for a given network, the
# weights will need to be downloaded first -- depending on which
# network you are using, the weights can be 90-575MB, so be
# patient; the weights will be cached and subsequent runs of this
# script will be *much* faster)
print("[INFO] loading {}...".format(args["model"]))
Network = MODELS[args["model"]]
model = Network(weights="imagenet")

# load the input image using the Keras helper utility while ensuring
# the image is resized to `inputShape`, the required input dimensions
# for the ImageNet pre-trained network
print("[INFO] loading and pre-processing image...")
image = load_img(args["image"], target_size=inputShape)
image = img_to_array(image)

# our input image is now represented as a NumPy array of shape
# (inputShape[0], inputShape[1], 3) however we need to expand the
# dimension by making the shape (1, inputShape[0], inputShape[1], 3)
# so we can pass it through thenetwork
image = np.expand_dims(image, axis=0)

# pre-process the image using the appropriate function based on the
# model that has been loaded (i.e., mean subtraction, scaling, etc.)
image = preprocess(image)


# classify the image
print("[INFO] classifying image with '{}'...".format(args["model"]))
preds = model.predict(image)
P = imagenet_utils.decode_predictions(preds)

# loop over the predictions and display the rank-5 predictions +
# probabilities to our terminal
for (i, (imagenetID, label, prob)) in enumerate(P[0]):
	print("{}. {}: {:.2f}%".format(i + 1, label, prob * 100))

# load the image via OpenCV, draw the top prediction on the image,
# and display the image to our screen
orig = cv2.imread(args["image"])
(imagenetID, label, prob) = P[0][0]
cv2.putText(orig, "Label: {}, {:.2f}%".format(label, prob * 100),
	(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
cv2.imshow("Classification", orig)
cv2.waitKey(0)

# Usage
# python classify_image.py --image images/soccer_ball.jpg --model vgg16
# python classify_image.py --image images/bmw.png --model vgg19
# python classify_image.py --image images/clint_eastwood.jpg --model resnet
# python classify_image.py --image images/jemma.png --model resnet
# python classify_image.py --image images/boat.png --model inception
# python classify_image.py --image images/office.png --model inception
# python classify_image.py --image images/scotch.png --model xception
# python classify_image.py --image images/tv.png --model vgg16



##########################################################################################
#
#	Running fast.ai course notebook on Floyd (Floydhub)
#	https://shaoanlu.wordpress.com/2017/03/06/floydhub/
#
##########################################################################################

pip install -U floyd-cli
floyd login
git clone https://github.com/fastai/courses.git
cd courses/deeplearning/nbs
$ floyd init YourFirstProjectName
floyd run --mode jupyter --env theano:py2 --gpu

# https://keras.io/applications/#vgg16

Download catsdogs.zip in Jupyter
https://shaoanlu.wordpress.com/2017/03/15/floydhub-downloading-data/

floyd data init catsdogs.zipped
floyd data upload