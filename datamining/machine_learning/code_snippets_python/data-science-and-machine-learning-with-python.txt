###############################################################
#
#   Data Science, Deep Learning, & Machine Learning with Python with Frank Kane - Founder, Sundog Education
#   https://www.udemy.com/data-science-and-machine-learning-with-python-hands-on/learn/v4/overview
#
#   !pip install pydotplus
#
#   http://sundog-education.com/datascience/
#   http://www.datasciencemadesimple.com/box-plot-in-python/
#
#   https://github.com/divyakarippath/DataScience
#
################################################################

# -----------------------------------------------------------
# import modules
import numpy as np
a = np.random.normal(25.0,5.0,10)
print a

# -----------------------------------------------------------
# lists
x = [1,2,3,4,5]
x.extend([44,88])
x.append(19)
x.sort(reverse=True)


# -----------------------------------------------------------
# Tuples
x = (1,2,3)
x[2]
(age,income) = "32,1200000".split(',')
print age


# -----------------------------------------------------------
# Dictionaries
cp = {}
cp["one"] = "Done"
cp["two"] = "Donot
print cp["one"]
for ship in cp:
  print ship + ":" + cp[ship]


# -----------------------------------------------------------
# functions
def SquareIt(x):
    return x * x
print SquareIt(2)

def Dothis(f,x)
  return f(x)
print Dothis(SquareIt,3)
print Dothis(lambda x: x*x*x, 3)


# -----------------------------------------------------------
# looping
for x in range(10):
	print x,


x=0
while(x<10)
  print x,
x+=1



# -----------------------------------------------------------
# df panda examples
# -----------------------------------------------------------
%matplotlib inline
import numpy as np
import pandas as pd
df = pd.read_csv("some.csv")
df.head()
df.head(10) # first 10 rows
df.tail(4) # last 4 rows
df.shape() # row cols info
df.size() # max rows * count
len(df) # 13 - count rows
df.columns # prints header
df['Hired'] # extract first column
df['Hired'][:5] # extract first 5 rows
df['Hired'][5] # extract  5 rows
df[['Hired','Years']] # extract 2 columns
df.sort_values(['Years']) # sort column


dc = df['Years'].value_counts() # count by group
dc.plot(kind="bar")


# -----------------------------------------------------------
# data types Lek8
# -----------------------------------------------------------
numerical (int)
categorical (boolean, string, category)
ordinal (mix, rating)



# -----------------------------------------------------------
mean - sum / count()
median - middle avg
mode - common value
# -----------------------------------------------------------
import numpy as np
incomes = np.random.normal(27000,15000,10000)
np.mean(incomes) # 27099

import matplotlib.pyplot as plt
plt.hist(incomes,50)
plt.show()

np.median(incomes) # 26000
incomes = np.append(incomes,[100000000])


# get mode
ages = np.random.randint(18, high=90, size=500)
ages
from scipy import stats
stats.mode(ages) # count common value



# -----------------------------------------------------------
# Variation and Standard Deviation
# -----------------------------------------------------------
import numpy as np
import matplotlib.pyplot as plt
incomes = np.random.normal(100.0,20.0,10000)
plt.hist(incomes,50)
plt.show()
incomes.std() # Standard Deviation
incomes.var() # Variation



# -----------------------------------------------------------
# Probability Density Function; Probability Mass Function
# -----------------------------------------------------------
# Gaussian
import numpy as np
import matplotlib.pyplot as plt
incomes = np.random.normal(-10.0,10.0,10000)
plt.hist(incomes,50)
plt.show()
from scipy.stats import norm
import matplotlib.pyplot as plt
x = np.arange(-3,3,0.001)
plt.plot(x, norm.pdf(x))

# Exponential PDF
import numpy as np
import matplotlib.pyplot as plt
mu = 5.0
sigma = 2.0
values = np.random.normal(mu,sigma,10000)
plt.hist(incomes,50)
plt.show()
from scipy.stats import norm
import matplotlib.pyplot as plt
x = np.arange(0,10,0.001)
plt.plot(x, expon.pdf(x))

# Binomial Probabilty Mass Function
import numpy as np
import matplotlib.pyplot as plt
n,p = 10,0.5
x = np.arange(0,10,0.001)
plt.plot(x, binom.pmf(x,n,p))

# Poisson Probabilty Mass Function
from scipy.stats import poisson
import matplotlib.pyplot as plt
mu = 500
x = np.arange(400,600,0.5)
plt.plot(x, poisson.pmf(x,mu))





# -----------------------------------------------------------
# Percentiles and Moments - quartile > mean , moment, skew, kurtosis
# -----------------------------------------------------------
import numpy as np
import matplotlib.pyplot as plt
vals = np.random.normal(0,0.5,10000)
plt.hist(vals,50)
plt.show()
np.mean(vals) # mean - firs moment
np.var(vals) # variance - second moment
import scipy.stats as sp
sp.skew(vals) # skew - third moment
sp.kurtosis(vals) # kurtosis - fourth moment




# -----------------------------------------------------------
# A Crash Course in matplotlib - 15
# -----------------------------------------------------------
from scipy.stats import norm
import matplotlib.pyplot as plt
x = np.arange(-3,3,0.001)
plt.plot(x,norm.pdf(x))
plt.plot(x,norm.pdf(x, 1.0, 0.5))
plt.show()
plt.savefig('/home/user/pydata/export/exp.png',format='png') #save as png

# use axes
axes = plt.axes()
axes.set_xlim(-5,5)
axes.set_ylim(0,0.1)
axes.set_xticks(-1,0,1)
axes.set_yticks(0,0.2,0.4,0.6)
plt.plot(x, norm.pdf(x), 'b-') # show a dash line as style
plt.plot(x, norm.pdf(x, 1.0, 0.5), 'r:') # show  or r--
plt.legend(['Desc1','Desc2'], loc=4) # add legend
plt.show()





# Sketch Path Filter
# showcase example code: xkcd.py
# http://matplotlib.org/xkcd/examples/showcase/xkcd.html
# https://jakevdp.github.io/blog/2013/07/10/XKCD-plots-in-matplotlib/

from matplotlib import pyplot as plt
import numpy as np
plt.xkcd()
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
ax.spines['right'].set_color('none')
ax.spines['top'].set_color('none')
plt.xticks([])
plt.yticks([])
ax.set_ylim([-30, 10])
data = np.ones(100)
data[70:] -= np.arange(30)
plt.annotate(
    'THE DAY I REALIZED\nI COULD COOK BACON\nWHENEVER I WANTED',
    xy=(70, 1), arrowprops=dict(arrowstyle='->'), xytext=(15, -10))

plt.plot(data)
plt.xlabel('time')
plt.ylabel('my overall health')
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
ax.bar([-0.125, 1.0-0.125], [0, 100], 0.25)
ax.spines['right'].set_color('none')
ax.spines['top'].set_color('none')
ax.xaxis.set_ticks_position('bottom')
ax.set_xticks([0, 1])
ax.set_xlim([-0.5, 1.5])
ax.set_ylim([0, 110])
ax.set_xticklabels(['CONFIRMED BY\nEXPERIMENT', 'REFUTED BY\nEXPERIMENT'])
plt.yticks([])
plt.title("CLAIMS OF SUPERNATURAL POWERS")
plt.show()



# pie chart
plt.rcdefaults() #remove xkcd mode
values = [12, 55, 4, 23, 77]
colors = ['r','g','b','c','m']
explode = [0, 0, 0.2, 0, 0]
labels = ['A','B','C','D','E']
plt.pie(values,colors=colors, labels=labels, explode=explode)
plt.title('some title')
plt.show()



# bar chart
values = [11,12,23,34,45]
colors = ['r','g','b','c','m']
plt.bar(range(0,5), values, colors = colors)
plt.show()




# scatter plot
X = randn(500)
Y = randn(500)
plt.scatter(X,Y)
plt.show()



# histogram
incomes = np.random.normal(27000,15000,10000)
plt.hist(incomes,50)
plt.show()



# box and whisker plot
http://www.datasciencemadesimple.com/box-plot-in-python/

import matplotlib.pyplot as plt
 value1 = [82,76,24,40,67,62,75,78,71,32,98,89,78,67,72,82,87,66,56,52]
value2=[62,5,91,25,36,32,96,95,3,90,95,32,27,55,100,15,71,11,37,21]
value3=[23,89,12,78,72,89,25,69,68,86,19,49,15,16,16,75,65,31,25,52]
value4=[59,73,70,16,81,61,88,98,10,87,29,72,16,23,72,88,78,99,75,30]
box_plot_data=[value1,value2,value3,value4]
plt.boxplot(box_plot_data)
plt.show()



# -----------------------------------------------------------
# Covariance and Correlation

def de_mean(x):
  xmean = mean(x)
  return [xi - mean for xi in x]

def covariance(x,y):
  n = len(x)
  return dot(de_mean(x), de_mean(y)) / (n-1)

psgeSpeeds = np.random.normal(3.0, 1.0, 1000)
purchareAmount = np.random.normal(50.0, 10.0, 1000)
scatter(psgeSpeeds,purchareAmount)
covariance(psgeSpeeds,purchareAmount)
numpy.corrcoef(psgeSpeeds,purchareAmount) # correlations




# -----------------------------------------------------------
# Conditional Probability - 17

http://www.cs.uni.edu/~campbell/stat/prob4.html
https://people.richland.edu/james/lecture/m170/ch05-rul.html

A = 60%
B = 80%
OUTPUT = 75%

P (A|B) = P(A,B) / P(A) = 0.6 / 0.8 = 0.75

from numpy import random
random.seed(0)
totals = {20:0, 30:0, 40:0}
purchases = {20:0, 30:0, 40:0}
totalPurchased = 0
for _ in range(1000): # random number of people
   ageDecade  = random.choice([20,30,40])
   purchaseProbability = float(ageDecade) / 100.0
   # purchaseProbability = 0.4
   totals[ageDecade] += 1
   if(random.random() < purchaseProbability ):
     totalPurchased +=1
     purchases[ageDecade] +=1

PEF = float(purchases[30]) / float(totals[30])
print "P | 30s",PEF
PF = float(totals[30]) / 100000.0
print "P | 30s",PF
PE = float(totalsPurchases) / 100000.0
print "P | Purchase",PE

print "P(30)P(Purchase):", PE * PF
print "P(30), P(Purchase):", float(purchases[30]) / 100000.0





# -----------------------------------------------------------
# Bayes Theorem

P(a|b) = P(a)P(b|a) / P(b)  = 0.003 * 0.99 / 0.013 = 22.8%




# -----------------------------------------------------------
#  Linear Regression
https://saileshdev.github.io/predmodels/
https://saileshdev.github.io/stats-prob/

Example based on Height/Weight of people

y = mx + b
r-squared - 0|1

import numpy as np
from pylab import *

pageSpeeds = np.random.normal(3.0, 1.0, 1000)
purchaseAmount = 100 - (pageSpeeds + np.random.normal(0, 0.1, 1000)) * 3
#so we are creatng 2 vars which linearly depend on each other
scatter(pageSpeeds, purchaseAmount)

from scipy import stats
slope, intercept, r_value, p_value, std_err = stats.linregress(pageSpeeds, purchaseAmount)
# so essentially tuple unpacking happens here
# slope and intercept are the parameters of the line that fits the model
# r_value**2 will talk about the quality of this linear model we are trying to fit

import matplotlib.pyplot as plt

def predict(x):
    return slope * x + intercept

fitLine = predict(pageSpeeds)
plt.scatter(pageSpeeds, purchaseAmount)
plt.plot(pageSpeeds, fitLine, c='r')
plt.show()








# -----------------------------------------------------------
# Polynomial Regression - Polynomial regression using python
https://saileshdev.github.io/predmodels/


from pylab import *
np.random.seed(2) #allows us to generate the same random values over and over again
pageSpeeds = np.random.normal(3.0, 1.0, 1000)
purchaseAmount = np.random.normal(50.0, 10.0, 1000) / pageSpeeds
scatter(pageSpeeds, purchaseAmount)
x = np.array(pageSpeeds)
y = np.array(purchaseAmount)

p4 = np.poly1d(np.polyfit(x, y, 4)) #so np.polyfit does the job and 4 means we need python to perform 4th degree polynomial regression
# np.polyfit returns the coefficients as np.ndarray
# np.ploy1d constructs the polynomial with those coeffiecients, so now p4(2) gives the value of the poly at 4

import matplotlib.pyplot as plt

xp = np.linspace(0, 7, 100)
# means start is 0 and end is 7 and we need 100 equi-spaced points
# in np.arange we specify start,stop and step(not no of points) unlike np.linspace
plt.scatter(x, y)
plt.plot(xp, p4(xp), c='r')
plt.show()

from sklearn.metrics import r2_score
r2 = r2_score(y, p4(x)) //r2_score is a func in sklearn.metrics
print r2







# -----------------------------------------------------------
# Multivariate Regression, and Predicting - more feature  - Multiple Regression
# https://github.com/divyakarippath/DataScience

price = a + b1(mileage) + b2(age) + b3(doors)

# for regression we can use only numeric data!

import pandas as pd
import statsmodels.api as sm
#Pandas is used to deal with tabular data
#read_excel returns a dataframe
df = pd.read_excel('http://cdn.sundog-soft.com/Udemy/DataScience/cars.xls')
#print first few lines
print df.count()
print df.head()

#Predict price based on mileage,model,and doors

df['Model_ord'] = pd.Categorical(df.Model).codes
print df.head()

x=df[['Mileage','Model_ord','Doors']]
y=df[['Price']]

x1 = sm.add_constant(x)
#print x1
est = sm.OLS(y,x).fit()
print est.summary()

#means of price for different number of doors
print y.groupby(df.Doors).mean()


import statsmodels.api as sm
from sklearn.preprocessing import StandarScaler
scale = StandarScaler()

X = df[['Mileage','Cylinder','Doors']]
Y = df[['Price']]

X[['Mileage','Cylinder','Doors']] = scale.fit_transform(X[['Mileage','Cylinder','Doors']].as_matrix())
print X
est = sm.OLS(y,X).fit()
est.summary()
y.groupby(df.Doors).mean()





# -----------------------------------------------------------
# Multi-Level Models Systems




# -----------------------------------------------------------
# Supervised vs. Unsupervised Learning, and Train - Machine Learning

- clustering movies with Unsupervised Learning
- predict car price with Supervised Learning

- train set - build model
- test set - compare models
- check overfitting
- K-fold Cross Validation




import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

np.random.seed(2)
pageSpeeds = np.random.normal(3.0,1.0,100)
purchaseAmt = np.random.normal(50.0,30.0,100)/pageSpeeds

#plt.scatter(pageSpeeds,purchaseAmt)
#plt.show()

trainX = pageSpeeds[:80]
trainY = purchaseAmt[:80]

testX = pageSpeeds[80:]
testY = purchaseAmt[80:]

#Train Set
x = np.array(trainX)
y=np.array(trainY)
p4 = np.poly1d(np.polyfit(x,y,8))

xp=np.linspace(0,7,100)
axes = plt.axes()
axes.set_xlim([0,7])
axes.set_ylim([0,200])
#plt.scatter(x,y)
#plt.plot(xp,p4(xp),c='red')
#plt.show()

#Test Set
testx = np.array(testX)
testy=np.array(testY)
plt.scatter(testx,testy)
plt.plot(xp,p4(xp),c='red')
plt.show()

#r2 score for test and train data sets
print r2_score(testy,p4(testx))
print r2_score(y,p4(x))



# -----------------------------------------------------------
# Bayesian Methods: Concepts

- spam filter
P(Spam|Free) = P(Spam) P(Free|Spam) / P (Free)


Naive Bayes - for independet data - CountVertorizer
vectorizer = CountVectorizer() / classifier= MultinomialNB()

https://github.com/divyakarippath/DataScience/DataScience/Udemy/DataScience and ML with Python/4.1_NaiveBayes.py




# -----------------------------------------------------------
# K-Means Clustering
https://github.com/divyakarippath/DataScience/DataScience/Udemy/DataScience and ML with Python/4.2_KMeans.py

clustering music, films =  unsupervised learning




# -----------------------------------------------------------
# resources 1

Predictive Analytics
https://saileshdev.github.io/predmodels/

Statistics and Probability
https://saileshdev.github.io/stats-prob/

Box plot in Python with matplotlib
http://www.datasciencemadesimple.com/box-plot-in-python/

Python – Pandas Data Structure
http://www.datasciencemadesimple.com/python-pandas-data-structure/


Intro to Computer Science
https://www.udacity.com/course/intro-to-computer-science--cs101#

Play Video: Linear Algebra - Foundations to Frontiers Linear Algebra - Foundations to Frontiers
https://www.edx.org/course/linear-algebra-foundations-frontiers-utaustinx-ut-5-02x

Introduction to Probability - The Science of Uncertainty
https://www.edx.org/course/introduction-probability-science-mitx-6-041x-2

Introduction to Statistics: Descriptive Statistics
https://www.edx.org/course/introduction-statistics-descriptive-uc-berkeleyx-stat2-1x

Explore Statistics with R
https://www.edx.org/course/explore-statistics-r-kix-kiexplorx-0

Calculus: Single Variable Part 1 - Functions Created by:  University of Pennsylvania
https://www.coursera.org/learn/single-variable-calculus

# -----------------------------------------------------------
# resources 2

https://people.richland.edu/james/lecture/m170/ch05-rul.html
https://www.algebra.com/algebra/homework/Probability-and-statistics/Probability-and-statistics.faq.question.40008.html
https://plot.ly/python/box-plots/
https://plot.ly/pandas/box-plots/
http://pandas.pydata.org/pandas-docs/version/0.13.1/visualization.html
https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html
https://github.com/jiayuasu/Synthetic-data-generator/blob/master/generator.py
https://docs.scipy.org/doc/scipy/reference/stats.html
https://www.tutorialspoint.com/python/list_append.htm
https://www.tutorialspoint.com/python/python_lists.htm
https://trinket.io/python
http://anh.cs.luc.edu/python/hands-on/3.1/handsonHtml/functions.html
https://www.python-kurs.eu/python3_funktionen.php
https://www.programiz.com/python-programming/function