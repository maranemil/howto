###############################################################
Read Iris Set in R - How to Perform K-Means Clustering in R Statistical Computing
https://www.youtube.com/watch?v=sAtnX3UJyN0
###############################################################

Iris = read.csv("/path/to/Iris.csv");
View(Iris);
Iris.features = Iris
View(Iris.features)
results <- kmeans(Iris.features ,3)
results$size

table(Iris$class, results$cluster)
plot(Iris[c("petal.length","petal.width")], col = results$cluster)
plot(Iris[c("petal.length","petal.width")], col = results$class)
plot(Iris[c("sepal.length","sepal.width")], col = results$class)

###############################################################
Cluster analysis in R K-Means
https://www.youtube.com/watch?v=PX5nSBGB5Tw
###############################################################

data(iris);
plot(iris);

# scale data
irisScaled <- scale(iris[,-5])
irisScaled

fitK <- kmeans(irisScaled,3)
fitK
str(fitK)
plot(iris,col = fitK$cluster)

k <- list()
for(i in 1:10){
	k[[[i]] <- kmeans(irisScaled,i)
}
k

betweenss_totss <- list()
for(i in 1:10){
   	betweenss_totss[[[i]] <- k[[[i]]$betweenss/k[[i]]$totss
}
plot(1:10, betweenss_totss, type = "b", ylab = "Between", xlab = "Clusters")
for(i in 1:4){
	plot(iris,col = k[[i]]$cluster)
}

# hierarchical
d <- dist(irisScaled)
fitH <- hclust(d,"ward.D2")
plot(fitH) # tree view plot
rect.hclust(fitH, k = 3, border = "red")
clusters <- cutree(fitH, 3)
clusters
plot(iris, col = clusters)

# model based
library(mclust)
fitM <- Mclust(irisScaled)
fitM
plot(fitM)

# density
install.packages("dbscan")
library(dbscan)
kNNdistplot(irisScaled, k = 3)
abline(h = 0.7, col = "red", lty = 2)
fitD <- dbscan(irisScaled, eps = , minPts = 5)
fitD


